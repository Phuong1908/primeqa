{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e93a22f",
   "metadata": {},
   "source": [
    "# Tutorial: Rerank search results using the ColBERT Reranker #\n",
    "\n",
    "In this tutorial, we will learn how to use a Neural Reranker to rerank results from a BM25 search.  The reranker is based on the ColBERT algorithm as described in Khattab et al., \"ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT\" [here](https://arxiv.org/pdf/2004.12832.pdf).\n",
    "\n",
    "For the purposes of making this tutorial easy to understand we show the steps using a very small document collection. Note that this technique can be used to scale to millions of documents. We have tested upto 21 million Wikipedia passages!!!\n",
    "\n",
    "The tutorial will take you through these three steps:\n",
    "\n",
    "1. Build a BM25 index over a small sample collection\n",
    "2. Query the BM25 index to obtain initial search results\n",
    "3. Rerank the initial results with a neural reranker to obtain the final search results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3128e2ba",
   "metadata": {},
   "source": [
    "## Preparing a Colab Environment to run this tutorial ##\n",
    "\n",
    "Make sure to \"Enable GPU Runtime\" -> make a URL with a page with screenshots on how to do this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "690bd474",
   "metadata": {},
   "source": [
    "## Installing PrimeQA ##\n",
    "\n",
    "First, we need to include the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39d213",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "\n",
    "# install primeqa\n",
    "!pip install primeqa\n",
    "\n",
    "# Java 11 is required\n",
    "!pip install install-jdk\n",
    "# import jdk\n",
    "# jdk.install('11')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad12a576",
   "metadata": {},
   "source": [
    "Next we set up some paths.  Please update the `output_dir` path to a location where you have write permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc2731",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a337e8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Setup paths \n",
    "output_dir = \"/tmp/primeqa-tutorial\" \n",
    "\n",
    "import os\n",
    "# create output directory if it does not exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# create the data directory\n",
    "data_dir = os.path.join(output_dir,'data')\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "downloaded_corpus_file = os.path.join(data_dir,\"sample-document-store.csv\")\n",
    "index_dir = os.path.join(output_dir,\"sample_bm25_index\")\n",
    "collection_file = os.path.join(data_dir,\"sample_collection.tsv\")\n",
    "\n",
    "# create the model directory\n",
    "model_dir = os.path.join(output_dir,'models')\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "reranker_model_path = os.path.join(model_dir, \"DrDecr.dnn\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "958b8898",
   "metadata": {},
   "source": [
    "## Pre-process your document collection here to be ready to be stored in your BM25 Search Index. ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the sample collection\n",
    "! pip install gdown\n",
    "! gdown  --id 1LULJRPgN_hfuI2kG-wH4FUwXCCdDh9zh --output {data_dir}/\n",
    "\n",
    "# format the sample collection for indexing\n",
    "import csv\n",
    "with open(collection_file, 'w') as out_f:\n",
    "    tsv_writer = csv.writer(out_f, quoting=csv.QUOTE_MINIMAL, lineterminator='\\n', delimiter='\\t')\n",
    "    tsv_writer.writerow( ('id','text','title') )\n",
    "    with open(downloaded_corpus_file) as in_f:\n",
    "        reader = csv.DictReader(in_f, delimiter=',',)\n",
    "        for i, row in enumerate(reader):\n",
    "            tsv_writer.writerow( (str(i+1), row['text'], row['title'] ))\n",
    "! head -2 {collection_file}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bd0acad",
   "metadata": {},
   "source": [
    "## Now we will use the PrimeQA BM25 Indexer to build an index ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b6bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from primeqa.components.indexer.sparse import BM25Indexer\n",
    "\n",
    "# Instantiate and ocnfigure the indexer\n",
    "indexer = BM25Indexer(index_root=output_dir, index_name=\"sample_index_bm25\")\n",
    "indexer.load()   # IMPORTANT: required to configure\n",
    "\n",
    "# Index the collection\n",
    "indexer.index(collection=collection_file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c76d8171",
   "metadata": {},
   "source": [
    "## Start asking Questions ##\n",
    "\n",
    "We're now ready to query the index we created.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from primeqa.components.retriever.sparse  import BM25Retriever\n",
    "import json\n",
    "question = ['what is the main mineral in lithium batteries ?']\n",
    "\n",
    "# Instantiate and configure the retriever\n",
    "print(output_dir)\n",
    "retriever = BM25Retriever(index_root=output_dir, index_name=\"sample_index_bm25\", collection=collection_file)\n",
    "retriever.load()\n",
    "\n",
    "# Search\n",
    "search_results = retriever.predict(question, max_num_documents=5)\n",
    "print(json.dumps(search_results,indent=2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9911fef9",
   "metadata": {},
   "source": [
    "## Rerank the BM25 search results with a Neural Reranker ##\n",
    "\n",
    "We will be using the DrDecr model trained on Natural Questions and XOR TyDI.  This is a model that has obtained SOTA results on the XORTyDI Retrieval task.  \n",
    "\n",
    "Here are the steps we will take:\n",
    "\n",
    "    1. Download the reranker model\n",
    "    2. Format search results for input to the Reranker\n",
    "    3. Initialize the PrimeQA ColBERTReranker\n",
    "    4. Rerank the BM25 search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50ee9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the reranker model\n",
    "! wget -P {model_dir} https://huggingface.co/PrimeQA/DrDecr_XOR-TyDi_whitebox/resolve/main/DrDecr.dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73632d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reranker will encode the question and passages using the Reranker model and use the representations to compute a similarity score.\n",
    "# We will take the BM25 search results, obtain the passage texts and format the input to the reranker\n",
    "\n",
    "# Load the corpus\n",
    "import csv\n",
    "id_to_document = {}\n",
    "with open(collection_file) as in_f:\n",
    "    reader = csv.DictReader(in_f, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        id_to_document[row['id']] = {\n",
    "            'document_id': row['id'],\n",
    "            'text': row['text'],\n",
    "            'title': row['title']\n",
    "        }\n",
    "        \n",
    "reranker_input = []\n",
    "for result in search_results[0]:\n",
    "    \n",
    "    reranker_input.append({\n",
    "        'document': id_to_document[result[0]],\n",
    "        'score': result[1]\n",
    "    })\n",
    "print(json.dumps(reranker_input,indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5db291f7",
   "metadata": {},
   "source": [
    "## Run the Reranker ##\n",
    "Next we will initialize the ColBERT Reranker with the DrDecr model and rerank the BM25 search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ColBERT Reranker\n",
    "from primeqa.components.reranker.colbert_reranker import ColBERTReranker\n",
    "\n",
    "# Instantiate the ColBERTReranker\n",
    "reranker = ColBERTReranker(reranker_model_path)\n",
    "reranker.load()\n",
    "\n",
    "# rerank the BM25 search result and output the top 3 hits\n",
    "reranked_results = reranker.predict(question, [reranker_input], max_num_documents=3)\n",
    "print(json.dumps(reranked_results,indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9770e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now print search results before and after reranking\n",
    "print(question)\n",
    "print(\"\\nTop answer before reranking\")\n",
    "print(reranker_input[0]['document']['title'],  reranker_input[0]['document']['text'])\n",
    "\n",
    "print(\"\\nTop answer before reranking\")\n",
    "print(reranked_results[0][0]['document']['title'],  reranked_results[0][0]['document']['text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
