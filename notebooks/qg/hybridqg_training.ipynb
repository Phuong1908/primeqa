{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multihop Hybrid (Table + text) Question Generation: Training example\n",
    "In this notebook, we will see how to fine-tune and evaluate a question generation model on HybridQA dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "We start by setting some parameters to configure the process.  Note that depending on the GPU being used you may need to tune the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path=\"t5-small\"\n",
    "modality=\"hybrid\"\n",
    "dataset_name=\"hybrid_qa\"\n",
    "max_len=200\n",
    "target_max_len=40\n",
    "output_dir=\"/dccstor/cssblr/rbhat//models/\"\n",
    "learning_rate=0.0001\n",
    "num_train_epochs=2\n",
    "per_device_train_batch_size=8\n",
    "per_device_eval_batch_size=32\n",
    "evaluation_strategy='epoch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 01:27:31.845509: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=learning_rate,\n",
    "    prediction_loss_only=True,\n",
    "    remove_unused_columns=False,\n",
    "    )\n",
    "training_args.predict_with_generate=True\n",
    "training_args.remove_unused_columns = False\n",
    "training_args.prediction_loss_only = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## HybridQA data\n",
    "Here we load one instance of HybridQA and visualize it. <font color='red'>This part of the code is not needed to train the model </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset hybrid_qa (/dccstor/cssblr/rbhat/.cache/hybrid_qa/hybrid_qa/1.0.0/fabdc38783449dd6cb1acd25621af97b871e218fc3ab608191d492b408a93ab8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"question_id\": \"0424073b0d76fcb3\",\n",
      "    \"question\": \"The tracks of what creature are found in the formation located in the largest country in Southern Europe ?\",\n",
      "    \"table_id\": \"List_of_stratigraphic_units_with_ornithischian_tracks_5\",\n",
      "    \"answer_text\": \"Pterosaur\",\n",
      "    \"question_postag\": \"DT NNS IN WP NN VBP VBN IN DT NN VBN IN DT JJS NN IN NNP NNP .\",\n",
      "    \"table\": {\n",
      "        \"url\": \"https://en.wikipedia.org/wiki/List_of_stratigraphic_units_with_ornithischian_tracks\",\n",
      "        \"title\": \"List of stratigraphic units with ornithischian tracks\",\n",
      "        \"header\": [\n",
      "            \"Name\",\n",
      "            \"Location\",\n",
      "            \"Description\"\n",
      "        ],\n",
      "        \"data\": [\n",
      "            {\n",
      "                \"value\": \"Aganane Formation\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/Aganane_Formation\",\n",
      "                        \"summary\": \"The Aganane Formation is a Pliensbachian geologic formation in Morocco . Fossil stegosaur and theropod tracks have been reported from the formation .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Morocco\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/Morocco\",\n",
      "                        \"summary\": \"Morocco ( /m\\u0259\\u02c8r\\u0252ko\\u028a/ ( listen ) ; Arabic : \\u0627\\u0644\\u0645\\u063a\\u0631\\u0628 , romanized : al-ma\\u0121hrib , lit . 'place the sun sets ; the west ' ; Standard Moroccan Tamazight : \\u2d4d\\u2d4e\\u2d56\\u2d54\\u2d49\\u2d31 , romanized : lme\\u0263rib ; French : Maroc ) , officially the Kingdom of Morocco ( Arabic : \\u0627\\u0644\\u0645\\u0645\\u0644\\u0643\\u0629 \\u0627\\u0644\\u0645\\u063a\\u0631\\u0628\\u064a\\u0629 , romanized : al-mamlakah al-maghribiyah , lit . 'The Western Kingdom ' ; Standard Moroccan Tamazight : \\u2d5c\\u2d30\\u2d33\\u2d4d\\u2d37\\u2d49\\u2d5c \\u2d4f \\u2d4d\\u2d4e\\u2d56\\u2d54\\u2d49\\u2d31 , romanized : tageldit n lma\\u0263rib ; French : Royaume du Maroc ) , is a country located in the Maghreb region of North Africa . It overlooks the Mediterranean Sea to the north and the Atlantic Ocean to the west , with land border with Algeria to the east and Western Sahara to the south ( status disputed ) . Morocco also claims the exclaves of Ceuta , Melilla and Pe\\u00f1\\u00f3n de V\\u00e9lez de la Gomera , all of them under Spanish jurisdiction , as well as several small Spanish-controlled islands of its coast . The capital is Rabat and the largest city is Casablanca . Morocco spans an area of 710,850 km2 ( 274,460 sq mi ) and has a population of over 36 million . Since the foundation of the first Moroccan state by Idris I in 788 AD , the country has been ruled by a series of independent dynasties , reaching its zenith under Almoravid and Almohad rule , when it spanned parts of Iberia and northwestern Africa . The Marinid and Saadi dynasties resisted foreign domination into the 17th century , allowing Morocco to remain the only northwest African country to avoid Ottoman occupation . The Alaouite dynasty , which rules to this day , seized power in 1631 . The country 's strategic location near the mouth of the Mediterranean attracted the interest of Europe , and in 1912 , Morocco was divided into French and Spanish protectorates , with an international zone in Tangier . It regained its independence in 1956 , and has since remained comparatively stable and prosperous by regional standards , with the fifth largest economy in Africa .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Description\",\n",
      "                \"urls\": []\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Broome Sandstone\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/Broome_Sandstone\",\n",
      "                        \"summary\": \"The Broome Sandstone is an Early Cretaceous geologic formation found in Western Australia , and formerly considered part of Dampier Group . Fossil stegosaur tracks belonging to the ichnogenus and species Garbina roeorum have been reported from the formation .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Australia\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/Australia\",\n",
      "                        \"summary\": \"Australia , officially the Commonwealth of Australia , is a sovereign country comprising the mainland of the Australian continent , the island of Tasmania , and numerous smaller islands . It is the largest country in Oceania and the world 's sixth-largest country by total area . The population of 26 million is highly urbanised and heavily concentrated on the eastern seaboard . Australia 's capital is Canberra , and its largest city is Sydney . The country 's other major metropolitan areas are Melbourne , Brisbane , Perth , and Adelaide . Indigenous Australians inhabited the continent for about 65,000 years prior to the first arrival of Dutch explorers in the early 17th century , who named it New Holland . In 1770 , Australia 's eastern half was claimed by Great Britain and initially settled through penal transportation to the colony of New South Wales from 26 January 1788 , a date which became Australia 's national day . The population grew steadily in subsequent decades , and by the time of an 1850s gold rush , most of the continent had been explored and an additional five self-governing crown colonies established . On 1 January 1901 , the six colonies federated , forming the Commonwealth of Australia . Australia has since maintained a stable liberal democratic political system that functions as a federal parliamentary constitutional monarchy , comprising six states and ten territories . Australia is the oldest , flattest , and driest inhabited continent , with the least fertile soils . It has a landmass of 7,617,930 square kilometres ( 2,941,300 sq mi ) .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Description\",\n",
      "                \"urls\": []\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Chacarilla Formation\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/Chacarilla_Formation\",\n",
      "                        \"summary\": \"The Chacarilla Formation ( Spanish : Formaci\\u00f3n Characilla ) is an Oxfordian to Early Cretaceous geologic formation of the Tarapac\\u00e1 Basin in northern Chile , close to the border with Bolivia . The marine and fluvial formation preserves several dinosaur trackways and has been declared a Natural Sanctuary ( Spanish : Santuario de la Naturaleza ) in 2004 .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Chile\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/Chile\",\n",
      "                        \"summary\": \"Chile ( /\\u02c8t\\u0283\\u026ali/ ( listen ) , /\\u02c8t\\u0283\\u026ale\\u026a/ ; Spanish : [ \\u02c8t\\u0283ile ] ) , [ nb 2 ] officially the Republic of Chile ( Spanish : Rep\\u00fablica de Chile ( help\\u00b7info ) ) , is a South American country occupying a long , narrow strip of land between the Andes to the east and the Pacific Ocean to the west . It borders Peru to the north , Bolivia to the northeast , Argentina to the east , and the Drake Passage in the far south . Chilean territory includes the Pacific islands of Juan Fern\\u00e1ndez , Salas y G\\u00f3mez , Desventuradas , and Easter Island in Oceania . Chile also claims about 1,250,000 square kilometres ( 480,000 sq mi ) of Antarctica under the Chilean Antarctic Territory . [ nb 3 ] , The arid Atacama Desert in northern Chile contains great mineral wealth , principally copper and lithium . The relatively small central area dominates in terms of population and agricultural resources , and is the cultural and political center from which Chile expanded in the late 19th century when it incorporated its northern and southern regions . Southern Chile is rich in forests and grazing lands , and features a string of volcanoes and lakes . The southern coast is a labyrinth of fjords , inlets , canals , twisting peninsulas , and islands . Spain conquered and colonized the region in the mid-16th century , replacing Inca rule in the north and centre , but failing to conquer the independent Mapuche who inhabited what is now south-central Chile . After declaring its independence from Spain in 1818 , Chile emerged in the 1830s as a relatively stable authoritarian republic . In the 19th century , Chile saw significant economic and territorial growth , ending Mapuche resistance in the 1880s and gaining its current northern territory in the War of the Pacific ( 1879-83 ) after defeating Peru and Bolivia . In the 1960s and 1970s , the country experienced severe left-right political polarization and turmoil .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Description\",\n",
      "                \"urls\": []\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Lastres Formation\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/Lastres_Formation\",\n",
      "                        \"summary\": \"The Lastres Formation is a geological formation located in Asturias province , northwestern Spain Fossil pterosaur tracks have been found in the formation .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Spain\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/Spain\",\n",
      "                        \"summary\": \"Spain ( Spanish : Espa\\u00f1a [ es\\u02c8pa\\u0272a ] ( listen ) ) , officially the Kingdom of Spain ( Spanish : Reino de Espa\\u00f1a ) , [ a ] [ b ] is a country in Southwestern Europe with some pockets of Spanish territory across the Strait of Gibraltar and the Atlantic Ocean . Its continental European territory is situated on the Iberian Peninsula . Its territory also includes two archipelagoes : the Canary Islands off the coast of Africa , and the Balearic Islands in the Mediterranean Sea . The African enclaves of Ceuta , Melilla , and Pe\\u00f1\\u00f3n de V\\u00e9lez de la Gomera make Spain the only European country to have a physical border with an African country ( Morocco ) . [ h ] Several small islands in the Alboran Sea are also part of Spanish territory . The country 's mainland is bordered to the south and east by the Mediterranean Sea except for a small land boundary with Gibraltar ; to the north and northeast by France , Andorra , and the Bay of Biscay ; and to the west and northwest by Portugal and the Atlantic Ocean . With an area of 505,990 km2 ( 195,360 sq mi ) , Spain is the largest country in Southern Europe , the second largest country in Western Europe and the European Union , and the fourth largest country in the European continent . By population ( about 47 million ) , Spain is the sixth largest in Europe and the fifth in the European Union . Spain 's capital and largest city is Madrid ; other major urban areas include Barcelona , Valencia , Seville , Zaragoza , M\\u00e1laga and Bilbao . Modern humans first arrived in the Iberian Peninsula around 35,000 years ago . Iberian cultures along with ancient Phoenician , Greek , Celtic and Carthaginian settlements developed on the peninsula until it came under Roman rule around 200 BCE , after which the region was named Hispania , based on the earlier Phoenician name Sp ( a ) n or Spania . At the end of the Western Roman Empire the Germanic tribal confederations migrated from Central Europe , invaded the Iberian peninsula and established relatively independent realms in its western provinces , including the Suebi , Alans and Vandals .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Description\",\n",
      "                \"urls\": []\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Morrison Formation\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/Morrison_Formation\",\n",
      "                        \"summary\": \"The Morrison Formation is a distinctive sequence of Upper Jurassic sedimentary rock found in the western United States which has been the most fertile source of dinosaur fossils in North America . It is composed of mudstone , sandstone , siltstone , and limestone and is light gray , greenish gray , or red . Most of the fossils occur in the green siltstone beds and lower sandstones , relics of the rivers and floodplains of the Jurassic period . It is centered in Wyoming and Colorado , with outcrops in Montana , North Dakota , South Dakota , Nebraska , Kansas , the panhandles of Oklahoma and Texas , New Mexico , Arizona , Utah , and Idaho . Equivalent rocks under different names are found in Canada . It covers an area of 1.5 million square kilometers ( 600,000 square miles ) , although only a tiny fraction is exposed and accessible to geologists and paleontologists . Over 75% is still buried under the prairie to the east , and much of its western paleogeographic extent was eroded during exhumation of the Rocky Mountains . It was named after Morrison , Colorado , where the first fossils in the formation were discovered by Arthur Lakes in 1877 . That same year , it became the center of the Bone Wars , a fossil-collecting rivalry between early paleontologists Othniel Charles Marsh and Edward Drinker Cope . In Colorado , New Mexico , and Utah , the Morrison Formation was a major source of uranium ore .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"USA\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/United_States\",\n",
      "                        \"summary\": \"The United States of America ( USA ) , commonly known as the United States ( U.S. or US ) or America , is a country consisting of 50 states , a federal district , five major self-governing territories , and various possessions . [ g ] At 3.8 million square miles ( 9.8 million km2 ) , it is the world 's third or fourth-largest country by total area [ b ] and is slightly smaller than the entire continent of Europe . Most of the country is located in central North America between Canada and Mexico . With an estimated population of over 328 million , the U.S. is the third most populous country in the world . The capital is Washington , D.C. , and the most populous city is New York City . Paleo-Indians migrated from Siberia to the North American mainland at least 12,000 years ago . European colonization began in the 16th century . The United States emerged from the thirteen British colonies established along the East Coast . Numerous disputes between Great Britain and the colonies led to the American Revolutionary War lasting between 1775 and 1783 , leading to independence . The United States embarked on a vigorous expansion across North America throughout the 19th century - gradually acquiring new territories , displacing Native Americans , and admitting new states - until by 1848 it spanned the continent . During the second half of the 19th century , the American Civil War led to the abolition of slavery in the United States . The Spanish-American War and World War I confirmed the country 's status as a global military power .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Description\",\n",
      "                \"urls\": []\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Patuxent Formation\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/Patuxent_Formation\",\n",
      "                        \"summary\": \"The Patuxent Formation is a Cretaceous geologic formation of the Atlantic coastal plain .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"USA\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/United_States\",\n",
      "                        \"summary\": \"The United States of America ( USA ) , commonly known as the United States ( U.S. or US ) or America , is a country consisting of 50 states , a federal district , five major self-governing territories , and various possessions . [ g ] At 3.8 million square miles ( 9.8 million km2 ) , it is the world 's third or fourth-largest country by total area [ b ] and is slightly smaller than the entire continent of Europe . Most of the country is located in central North America between Canada and Mexico . With an estimated population of over 328 million , the U.S. is the third most populous country in the world . The capital is Washington , D.C. , and the most populous city is New York City . Paleo-Indians migrated from Siberia to the North American mainland at least 12,000 years ago . European colonization began in the 16th century . The United States emerged from the thirteen British colonies established along the East Coast . Numerous disputes between Great Britain and the colonies led to the American Revolutionary War lasting between 1775 and 1783 , leading to independence . The United States embarked on a vigorous expansion across North America throughout the 19th century - gradually acquiring new territories , displacing Native Americans , and admitting new states - until by 1848 it spanned the continent . During the second half of the 19th century , the American Civil War led to the abolition of slavery in the United States . The Spanish-American War and World War I confirmed the country 's status as a global military power .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Description\",\n",
      "                \"urls\": []\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Saltwick Formation\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/Saltwick_Formation\",\n",
      "                        \"summary\": \"The Saltwick Formation is a Middle Jurassic geologic formation in Yorkshire and the western North Sea , it is primarily Aalenian in age . Fossil stegosaur tracks have been reported from the formation . An indeterminate sauropod has been reported from the formation .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"UK\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/United_Kingdom\",\n",
      "                        \"summary\": \"The United Kingdom of Great Britain and Northern Ireland , commonly known as the United Kingdom ( UK or U.K. ) or Britain , [ note 11 ] is a sovereign country located off the north\\u00adwestern coast of the European mainland . Existing under its current name since 1921 , the United Kingdom includes the island of Great Britain , the north\\u00adeastern part of the island of Ireland , and many smaller islands . Northern Ireland shares a land border with the Republic of Ireland . Otherwise , the United Kingdom is surrounded by the Atlantic Ocean , with the North Sea to the east , the English Channel to the south and the Celtic Sea to the southwest , giving it the 12th-longest coastline in the world . The Irish Sea separates Great Britain and Ireland . The total area of the United Kingdom is 94,000 square miles ( 240,000 km2 ) . The United Kingdom is a unitary parliamentary democracy and constitutional monarchy . [ note 12 ] The current monarch is Queen Elizabeth II , who has reigned since 1952 , making her the world 's longest-serving current head of state . The United Kingdom 's capital and largest city is London , a global city and financial centre with an urban area population of 10.3 million . Other major cities include Birmingham , Manchester , Glasgow , Leeds and Liverpool . The United Kingdom consists of four constituent countries : England , Scotland , Wales , and Northern Ireland . Their capitals are London , Edinburgh , Cardiff , and Belfast , respectively .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Description\",\n",
      "                \"urls\": []\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Walloon Group\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/Walloon_Group\",\n",
      "                        \"summary\": \"The Walloon Coal Measures are a Late Jurassic geologic subgroup in Queensland , Australia . Deposited within the Surat Basin it is Oxfordian to early Tithonian in age based on lead-uranium dating of tuffites within the unit . The dinosaur Rhoetosaurus is known from the unit .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Australia\",\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"url\": \"/wiki/Australia\",\n",
      "                        \"summary\": \"Australia , officially the Commonwealth of Australia , is a sovereign country comprising the mainland of the Australian continent , the island of Tasmania , and numerous smaller islands . It is the largest country in Oceania and the world 's sixth-largest country by total area . The population of 26 million is highly urbanised and heavily concentrated on the eastern seaboard . Australia 's capital is Canberra , and its largest city is Sydney . The country 's other major metropolitan areas are Melbourne , Brisbane , Perth , and Adelaide . Indigenous Australians inhabited the continent for about 65,000 years prior to the first arrival of Dutch explorers in the early 17th century , who named it New Holland . In 1770 , Australia 's eastern half was claimed by Great Britain and initially settled through penal transportation to the colony of New South Wales from 26 January 1788 , a date which became Australia 's national day . The population grew steadily in subsequent decades , and by the time of an 1850s gold rush , most of the continent had been explored and an additional five self-governing crown colonies established . On 1 January 1901 , the six colonies federated , forming the Commonwealth of Australia . Australia has since maintained a stable liberal democratic political system that functions as a federal parliamentary constitutional monarchy , comprising six states and ten territories . Australia is the oldest , flattest , and driest inhabited continent , with the least fertile soils . It has a landmass of 7,617,930 square kilometres ( 2,941,300 sq mi ) .\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"value\": \"Description\",\n",
      "                \"urls\": []\n",
      "            }\n",
      "        ],\n",
      "        \"section_title\": \"Thyreophorans -- Stegosaurs\",\n",
      "        \"section_text\": \"\",\n",
      "        \"uid\": \"List_of_stratigraphic_units_with_ornithischian_tracks_5\",\n",
      "        \"intro\": \"List of dinosaur-bearing rock formations\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "def print_hybridqa_instance(train_instance):\n",
    "    print(json.dumps(train_instance, indent=4))\n",
    "\n",
    "train_instance = load_dataset('hybrid_qa', split='train[1001:1002]')[0]\n",
    "print_hybridqa_instance(train_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Loading the Model\n",
    "\n",
    "Here we load the model based on the model_name and modality parameter set above. For HybridQA we keep modality='hybrid'. Other options are modality='table' and modality='passage'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /dccstor/cssblr/rbhat/.cache/models--t5-small/snapshots/d78aea13fa7ecd06c29e3e46195d6341255065d5/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.22.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /dccstor/cssblr/rbhat/.cache/models--t5-small/snapshots/d78aea13fa7ecd06c29e3e46195d6341255065d5/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at /dccstor/cssblr/rbhat/.cache/models--t5-small/snapshots/d78aea13fa7ecd06c29e3e46195d6341255065d5/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.22.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32128, 512]) torch.Size([32128, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spiece.model from cache at /dccstor/cssblr/rbhat/.cache/models--t5-small/snapshots/d78aea13fa7ecd06c29e3e46195d6341255065d5/spiece.model\n",
      "loading file tokenizer.json from cache at /dccstor/cssblr/rbhat/.cache/models--t5-small/snapshots/d78aea13fa7ecd06c29e3e46195d6341255065d5/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /dccstor/cssblr/rbhat/.cache/models--t5-small/snapshots/d78aea13fa7ecd06c29e3e46195d6341255065d5/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.22.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32128, 512]) torch.Size([32100, 512])\n"
     ]
    }
   ],
   "source": [
    "from primeqa.qg.models.qg_model import QGModel\n",
    "\n",
    "qg_model = QGModel(model_name_or_path, modality=modality, lang='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "Here we process and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset hybrid_qa (/dccstor/cssblr/rbhat/.cache/hybrid_qa/hybrid_qa/1.0.0/fabdc38783449dd6cb1acd25621af97b871e218fc3ab608191d492b408a93ab8)\n",
      "Parameter 'function'=<function HybridQAProcessor.preprocess_data at 0x7f277a1d5940> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac2043c0c3a4d4883b41c2315b8a5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting chains: 0it [00:00, ?it/s]\u001b[A\n",
      "Extracting chains: 1it [00:06,  6.14s/it]\u001b[A\n",
      "Extracting chains: 2it [00:06,  2.71s/it]\u001b[A\n",
      "Extracting chains: 3it [00:08,  2.52s/it]\u001b[A\n",
      "Extracting chains: 4it [00:09,  1.85s/it]\u001b[A\n",
      "Extracting chains: 6it [00:10,  1.06s/it]\u001b[A\n",
      "Extracting chains: 7it [00:11,  1.23s/it]\u001b[A\n",
      "Extracting chains: 8it [00:12,  1.06s/it]\u001b[A\n",
      "Extracting chains: 9it [00:14,  1.41s/it]\u001b[A\n",
      "Extracting chains: 10it [00:15,  1.17s/it]\u001b[A\n",
      "Extracting chains: 14it [00:18,  1.05it/s]\u001b[A\n",
      "Extracting chains: 15it [00:19,  1.12it/s]\u001b[A\n",
      "Extracting chains: 16it [00:29,  2.81s/it]\u001b[A\n",
      "Extracting chains: 17it [00:30,  2.43s/it]\u001b[A\n",
      "Extracting chains: 19it [00:32,  1.85s/it]\u001b[A\n",
      "Extracting chains: 20it [00:33,  1.70s/it]\u001b[A\n",
      "Extracting chains: 21it [00:34,  1.40s/it]\u001b[A\n",
      "Extracting chains: 22it [00:35,  1.44s/it]\u001b[A\n",
      "Extracting chains: 23it [00:36,  1.38s/it]\u001b[A\n",
      "Extracting chains: 24it [00:41,  2.34s/it]\u001b[A\n",
      "Extracting chains: 27it [00:43,  1.35s/it]\u001b[A\n",
      "Extracting chains: 28it [00:45,  1.51s/it]\u001b[A\n",
      "Extracting chains: 29it [00:46,  1.39s/it]\u001b[A\n",
      "Extracting chains: 30it [00:47,  1.35s/it]\u001b[A\n",
      "Extracting chains: 31it [00:52,  2.23s/it]\u001b[A\n",
      "Extracting chains: 32it [00:52,  1.72s/it]\u001b[A\n",
      "Extracting chains: 33it [00:53,  1.34s/it]\u001b[A\n",
      "Extracting chains: 34it [00:55,  1.70s/it]\u001b[A\n",
      "Extracting chains: 35it [00:56,  1.42s/it]\u001b[A\n",
      "Extracting chains: 38it [00:57,  1.21it/s]\u001b[A\n",
      "Extracting chains: 39it [00:58,  1.08it/s]\u001b[A\n",
      "Extracting chains: 40it [01:00,  1.03s/it]\u001b[A\n",
      "Extracting chains: 41it [01:02,  1.32s/it]\u001b[A\n",
      "Extracting chains: 45it [01:02,  1.76it/s]\u001b[A\n",
      "Extracting chains: 47it [01:04,  1.61it/s]\u001b[A\n",
      "Extracting chains: 48it [01:04,  1.58it/s]\u001b[A\n",
      "Extracting chains: 49it [01:04,  1.88it/s]\u001b[A\n",
      "Extracting chains: 51it [01:05,  1.90it/s]\u001b[A\n",
      "Extracting chains: 52it [01:07,  1.34it/s]\u001b[A\n",
      "Extracting chains: 53it [01:08,  1.27it/s]\u001b[A\n",
      "Extracting chains: 54it [01:10,  1.19s/it]\u001b[A\n",
      "Extracting chains: 55it [01:12,  1.26s/it]\u001b[A\n",
      "Extracting chains: 56it [01:14,  1.50s/it]\u001b[A\n",
      "Extracting chains: 57it [01:14,  1.13s/it]\u001b[A\n",
      "Extracting chains: 58it [01:17,  1.49s/it]\u001b[A\n",
      "Extracting chains: 63it [01:18,  1.42it/s]\u001b[A\n",
      "Extracting chains: 64it [01:21,  1.02s/it]\u001b[A\n",
      "Extracting chains: 65it [01:21,  1.12it/s]\u001b[A\n",
      "Extracting chains: 66it [01:22,  1.13it/s]\u001b[A\n",
      "Extracting chains: 67it [01:24,  1.18s/it]\u001b[A\n",
      "Extracting chains: 69it [01:25,  1.22it/s]\u001b[A\n",
      "Extracting chains: 70it [01:28,  1.47s/it]\u001b[A\n",
      "Extracting chains: 73it [01:30,  1.06it/s]\u001b[A\n",
      "Extracting chains: 74it [01:31,  1.02s/it]\u001b[A\n",
      "Extracting chains: 76it [01:31,  1.44it/s]\u001b[A\n",
      "Extracting chains: 77it [01:33,  1.21it/s]\u001b[A\n",
      "Extracting chains: 78it [01:34,  1.00it/s]\u001b[A\n",
      "Extracting chains: 79it [01:37,  1.52s/it]\u001b[A\n",
      "Extracting chains: 80it [01:39,  1.64s/it]\u001b[A\n",
      "Extracting chains: 81it [01:42,  1.83s/it]\u001b[A\n",
      "Extracting chains: 82it [01:44,  1.95s/it]\u001b[A\n",
      "Extracting chains: 83it [01:46,  1.91s/it]\u001b[A\n",
      "Extracting chains: 84it [01:47,  1.83s/it]\u001b[A\n",
      "Extracting chains: 85it [01:48,  1.42s/it]\u001b[A\n",
      "Extracting chains: 86it [01:49,  1.41s/it]\u001b[A\n",
      "Extracting chains: 87it [01:50,  1.21s/it]\u001b[A\n",
      "Extracting chains: 88it [01:51,  1.27s/it]\u001b[A\n",
      "Extracting chains: 89it [01:53,  1.50s/it]\u001b[A\n",
      "Extracting chains: 90it [01:56,  1.78s/it]\u001b[A\n",
      "Extracting chains: 91it [02:00,  2.57s/it]\u001b[A\n",
      "Extracting chains: 92it [02:04,  3.04s/it]\u001b[A\n",
      "Extracting chains: 93it [02:05,  2.29s/it]\u001b[A\n",
      "Extracting chains: 94it [02:06,  1.89s/it]\u001b[A\n",
      "Extracting chains: 96it [02:09,  1.80s/it]\u001b[A\n",
      "Extracting chains: 97it [02:11,  1.78s/it]\u001b[A\n",
      "Extracting chains: 98it [02:12,  1.58s/it]\u001b[A\n",
      "Extracting chains: 99it [02:13,  1.41s/it]\u001b[A\n",
      "Extracting chains: 100it [02:14,  1.35s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037a1c8e035142e6af31908705774678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/u/rbhat/.conda/envs/bhat/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2302: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Reusing dataset hybrid_qa (/dccstor/cssblr/rbhat/.cache/hybrid_qa/hybrid_qa/1.0.0/fabdc38783449dd6cb1acd25621af97b871e218fc3ab608191d492b408a93ab8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067fcf1afe53466ca57b2fc61dfeca94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting chains: 0it [00:00, ?it/s]\u001b[A\n",
      "Extracting chains: 1it [00:12, 12.67s/it]\u001b[A\n",
      "Extracting chains: 2it [00:13,  5.61s/it]\u001b[A\n",
      "Extracting chains: 3it [00:17,  5.10s/it]\u001b[A\n",
      "Extracting chains: 4it [00:18,  3.27s/it]\u001b[A\n",
      "Extracting chains: 5it [00:19,  2.39s/it]\u001b[A\n",
      "Extracting chains: 6it [00:22,  2.74s/it]\u001b[A\n",
      "Extracting chains: 9it [00:24,  1.41s/it]\u001b[A\n",
      "Extracting chains: 11it [00:24,  1.07s/it]\u001b[A\n",
      "Extracting chains: 12it [00:25,  1.11it/s]\u001b[A\n",
      "Extracting chains: 13it [00:25,  1.26it/s]\u001b[A\n",
      "Extracting chains: 14it [00:26,  1.16it/s]\u001b[A\n",
      "Extracting chains: 15it [00:39,  3.91s/it]\u001b[A\n",
      "Extracting chains: 16it [00:39,  2.92s/it]\u001b[A\n",
      "Extracting chains: 17it [00:40,  2.43s/it]\u001b[A\n",
      "Extracting chains: 18it [00:41,  2.02s/it]\u001b[A\n",
      "Extracting chains: 20it [00:49,  2.80s/it]\u001b[A\n",
      "Extracting chains: 22it [00:49,  1.77s/it]\u001b[A\n",
      "Extracting chains: 23it [00:51,  1.80s/it]\u001b[A\n",
      "Extracting chains: 24it [00:59,  3.26s/it]\u001b[A\n",
      "Extracting chains: 25it [01:00,  2.58s/it]\u001b[A\n",
      "Extracting chains: 26it [01:01,  2.25s/it]\u001b[A\n",
      "Extracting chains: 27it [01:01,  1.80s/it]\u001b[A\n",
      "Extracting chains: 28it [01:03,  1.60s/it]\u001b[A\n",
      "Extracting chains: 29it [01:05,  1.93s/it]\u001b[A\n",
      "Extracting chains: 30it [01:08,  2.19s/it]\u001b[A\n",
      "Extracting chains: 31it [01:08,  1.62s/it]\u001b[A\n",
      "Extracting chains: 32it [01:11,  1.81s/it]\u001b[A\n",
      "Extracting chains: 33it [01:11,  1.51s/it]\u001b[A\n",
      "Extracting chains: 36it [01:13,  1.16it/s]\u001b[A\n",
      "Extracting chains: 37it [01:15,  1.22s/it]\u001b[A\n",
      "Extracting chains: 38it [01:17,  1.41s/it]\u001b[A\n",
      "Extracting chains: 39it [01:21,  1.96s/it]\u001b[A\n",
      "Extracting chains: 40it [01:32,  4.31s/it]\u001b[A\n",
      "Extracting chains: 41it [01:32,  3.31s/it]\u001b[A\n",
      "Extracting chains: 42it [01:33,  2.57s/it]\u001b[A\n",
      "Extracting chains: 43it [01:36,  2.79s/it]\u001b[A\n",
      "Extracting chains: 44it [01:38,  2.36s/it]\u001b[A\n",
      "Extracting chains: 45it [01:57,  7.21s/it]\u001b[A\n",
      "Extracting chains: 46it [02:07,  8.03s/it]\u001b[A\n",
      "Extracting chains: 48it [02:07,  4.38s/it]\u001b[A\n",
      "Extracting chains: 49it [02:09,  3.93s/it]\u001b[A\n",
      "Extracting chains: 50it [02:10,  2.61s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "073c901c59704f24988565b103d720da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'input', 'input_ids', 'attention_mask', 'target_ids', 'target_attention_mask'],\n",
      "    num_rows: 75\n",
      "})\n",
      "Dataset({\n",
      "    features: ['label', 'input', 'input_ids', 'attention_mask', 'target_ids', 'target_attention_mask'],\n",
      "    num_rows: 42\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from primeqa.qg.processors.data_loader import QGDataLoader\n",
    "\n",
    "qgdl = QGDataLoader(\n",
    "    tokenizer=qg_model.tokenizer,\n",
    "    modality=modality,\n",
    "    dataset_name=dataset_name,\n",
    "    input_max_len=max_len,\n",
    "    target_max_len=target_max_len\n",
    "    )\n",
    "\n",
    "train_dataset = qgdl.create(dataset_split=\"train[:100]\")\n",
    "valid_dataset = qgdl.create(dataset_split=\"validation[:50]\")\n",
    "print(train_dataset)\n",
    "print(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using QGTrainer\n",
    "Here we create a QG trainer with the training arguments defined above and use it to train on HybridQA training data (or any custom data following the same format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/rbhat/.conda/envs/bhat/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 75\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.373989</td>\n",
       "      <td>16.859800</td>\n",
       "      <td>3.347400</td>\n",
       "      <td>14.724100</td>\n",
       "      <td>14.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.297106</td>\n",
       "      <td>17.300300</td>\n",
       "      <td>2.906800</td>\n",
       "      <td>14.761300</td>\n",
       "      <td>14.817400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to /dccstor/cssblr/rbhat//models/\n",
      "Configuration saved in /dccstor/cssblr/rbhat//models/config.json\n",
      "Model weights saved in /dccstor/cssblr/rbhat//models/pytorch_model.bin\n",
      "tokenizer config file saved in /dccstor/cssblr/rbhat//models/tokenizer_config.json\n",
      "Special tokens file saved in /dccstor/cssblr/rbhat//models/special_tokens_map.json\n",
      "Copy vocab file to /dccstor/cssblr/rbhat//models/spiece.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 49.5407, 'train_samples_per_second': 3.028, 'train_steps_per_second': 0.404, 'total_flos': 10891100160000.0, 'train_loss': 3.7156166076660155, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from primeqa.qg.trainers.qg_trainer import QGTrainer\n",
    "from primeqa.qg.utils.data_collator import T2TDataCollator\n",
    "from primeqa.qg.metrics.generation_metrics import rouge_metrics\n",
    "\n",
    "compute_metrics = rouge_metrics(qg_model.tokenizer)\n",
    "\n",
    "trainer = QGTrainer(\n",
    "    model=qg_model.model,\n",
    "    tokenizer = qg_model.tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=T2TDataCollator(),\n",
    "    compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "train_results = trainer.train()\n",
    "trainer.save_model()\n",
    "print(train_results.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Here we evaluate the trained model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2971057891845703, 'eval_rouge1': 17.3003, 'eval_rouge2': 2.9068, 'eval_rougeL': 14.7613, 'eval_rougeLsum': 14.8174, 'eval_runtime': 3.7786, 'eval_samples_per_second': 11.115, 'eval_steps_per_second': 0.529, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2837b60cedc613a72d719d2d261dedab01e8683bba6b8605ad579171c0f5b25"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c35b992e6c7aefc6892dbea5982d2f0b243183ae5e95337e08b7ede6fdab7cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
