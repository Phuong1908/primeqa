{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764f905e",
   "metadata": {},
   "source": [
    "## Dense IR ##\n",
    "\n",
    "In this notebook, we show how to train a model, index data, and run search using Direct Passage Retrieval (DPR) based Neural IR, using techniques as described in Karpukhin et al., \"Dense Passage Retrieval for Open-Domain Question Answering\" [here](https://arxiv.org/pdf/2004.04906.pdf)\n",
    "\n",
    "In orded to run the cells (almost) instantaneously, we use trivial data sizes of training data and collection to search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf857d8e",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "If not already done, make sure to install PrimeQA with notebooks extras before getting started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e3426d",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "First, we need to include the required modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b5fa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/opt/share/cuda-10.1/x86_64'\n",
      "{\"time\":\"2022-10-26 15:42:31,560\", \"name\": \"faiss.loader\", \"level\": \"INFO\", \"message\": \"Loading faiss.\"}\n",
      "{\"time\":\"2022-10-26 15:42:32,053\", \"name\": \"faiss.loader\", \"level\": \"INFO\", \"message\": \"Successfully loaded faiss.\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse, sys\n",
    "\n",
    "import tempfile\n",
    "from unittest.mock import patch\n",
    "\n",
    "from primeqa.ir.dense.dpr_top.dpr.biencoder_trainer import BiEncoderTrainer\n",
    "from primeqa.ir.dense.dpr_top.dpr.index_simple_corpus import DPRIndexer\n",
    "from primeqa.ir.dense.dpr_top.dpr.searcher import DPRSearcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae55ff",
   "metadata": {},
   "source": [
    "## Training\n",
    "We will train a DPR model using a TSV file containing [query, positive document, negative document] triples. We use a small subset of the XOR-TyDi dataset, as described [here](https://nlp.cs.washington.edu/xorqa/)\n",
    "\n",
    "The path in `test_files_location` below points to the location of files used by the notebook, by default it points to the files used by CI testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97dc9583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpxyvdwant/output_dir\n"
     ]
    }
   ],
   "source": [
    "test_files_location = '../../../tests/resources/ir_dense'\n",
    "with tempfile.TemporaryDirectory() as working_dir:\n",
    "    output_dir=os.path.join(working_dir, 'output_dir')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(output_dir)\n",
    "text_triples_fn = os.path.join(test_files_location, \"xorqa.train_ir_negs_5_poss_1_001pct_at_0pct_en.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2089ecb",
   "metadata": {},
   "source": [
    "Here is an example of a training file record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2b9423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who maintained the throne for the longest time in China?</td>\n",
       "      <td>Kangxi Emperor The Kangxi Emperor's reign of 61 years makes him the longest-reigning emperor in Chinese history (although his grandson, the Qianlong Emperor, had the longest period of \"de facto\" power) and one of the longest-reigning rulers in the world. However, since he ascended the throne at the age of seven, actual power was held for six years by four regents and his grandmother, the Grand Empress Dowager Xiaozhuang.</td>\n",
       "      <td>Chiddy Bang new songs from the duo and in November 2009 debuted the group's first free mixtape entitled \"The Swelly Express\". On 28 April 2011 during the first-ever MTV O Music Awards, Anamege broke the Guinness World Record for Longest Freestyle Rap and Longest Marathon Rapping Record by freestyling for 9 hours, 18 minutes, and 22 seconds, stealing the throne from rapper M-Eighty, who originally broke the record in 2009 by rapping for 9 hours, 15 minutes and 15 seconds. Anamege had also beat Canadian rapper D.O. for Longest Marathon Rapping session, the previous record being for 8 hours and 45 minutes.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "data = pd.read_csv(text_triples_fn, sep='\\t', nrows=1, header=None)\n",
    "display(HTML(data.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed359e77",
   "metadata": {},
   "source": [
    "Here are the parameters of the training, corresponding to the command line arguments used with the top-level script (`run_ir.py`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c90ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_args = [\n",
    "    \"prog\",\n",
    "    \"--train_dir\", text_triples_fn,\n",
    "    \"--output_dir\", output_dir,\n",
    "    \"--full_train_batch_size\", \"1\",\n",
    "    \"--num_train_epochs\", \"1\",\n",
    "    \"--training_data_type\", \"text_triples\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603d92b",
   "metadata": {},
   "source": [
    "Next we run the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79502db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"time\":\"2022-10-26 15:42:37,396\", \"name\": \"primeqa.ir.dense.dpr_top.torch_util.hypers_base\", \"level\": \"INFO\", \"message\": \"world_rank 0 cuda_is_available False cuda_device_cnt 0 on cccxl009, CUDA_VISIBLE_DEVICES = NOT SET\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/26/2022 15:42:37 hypers_base.py:157 - On cccxl009, Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "10/26/2022 15:42:37 hypers_base.py:166 - hypers:\n",
      "{\n",
      "  \"local_rank\": -1,\n",
      "  \"global_rank\": 0,\n",
      "  \"world_size\": 1,\n",
      "  \"model_type\": \"\",\n",
      "  \"model_name_or_path\": \"\",\n",
      "  \"resume_from\": \"\",\n",
      "  \"config_name\": \"\",\n",
      "  \"tokenizer_name\": \"\",\n",
      "  \"cache_dir\": \"\",\n",
      "  \"do_lower_case\": false,\n",
      "  \"gradient_accumulation_steps\": 1,\n",
      "  \"learning_rate\": 2e-5,\n",
      "  \"weight_decay\": 0.0,\n",
      "  \"adam_epsilon\": 1e-8,\n",
      "  \"max_grad_norm\": 2.0,\n",
      "  \"warmup_instances\": 0,\n",
      "  \"warmup_fraction\": 0.0,\n",
      "  \"num_train_epochs\": 1,\n",
      "  \"no_cuda\": false,\n",
      "  \"n_gpu\": 0,\n",
      "  \"seed\": 42,\n",
      "  \"fp16\": false,\n",
      "  \"fp16_opt_level\": \"O1\",\n",
      "  \"full_train_batch_size\": 1,\n",
      "  \"per_gpu_eval_batch_size\": 8,\n",
      "  \"output_dir\": \"\\/tmp\\/tmpxyvdwant\\/output_dir\",\n",
      "  \"log_on_all_nodes\": false,\n",
      "  \"server_ip\": \"\",\n",
      "  \"server_port\": \"\",\n",
      "  \"qry_encoder_name_or_path\": \"facebook\\/dpr-question_encoder-multiset-base\",\n",
      "  \"ctx_encoder_name_or_path\": \"facebook\\/dpr-ctx_encoder-multiset-base\",\n",
      "  \"encoder_gpu_train_limit\": 8,\n",
      "  \"seq_len_q\": 64,\n",
      "  \"seq_len_c\": 128,\n",
      "  \"debug_location\": \"\",\n",
      "  \"sample_negative_from_top_k\": -1,\n",
      "  \"force_confict_free_batches\": false,\n",
      "  \"training_data_type\": \"text_triples\",\n",
      "  \"collection\": \"\",\n",
      "  \"queries\": \"\",\n",
      "  \"engine_type\": \"\",\n",
      "  \"do_train\": false,\n",
      "  \"train_dir\": \"..\\/..\\/..\\/tests\\/resources\\/ir_dense\\/xorqa.train_ir_negs_5_poss_1_001pct_at_0pct_en.tsv\",\n",
      "  \"positive_pids\": \"\",\n",
      "  \"num_instances\": -1,\n",
      "  \"resume_from_checkpoint\": \"\",\n",
      "  \"save_every_num_batches\": 0,\n",
      "  \"log_every_num_batches\": 0,\n",
      "  \"log_all_losses\": false,\n",
      "  \"max_negatives\": 0,\n",
      "  \"max_hard_negatives\": 1,\n",
      "  \"device\": \"cpu\",\n",
      "  \"per_gpu_train_batch_size\": 1,\n",
      "  \"stop_time\": \"None\"\n",
      "}\n",
      "10/26/2022 15:42:37 biencoder_trainer.py:49 - Counted num_instances = 5\n",
      "10/26/2022 15:42:38 biencoder_gcp.py:31 - BiEncoder: initializing from facebook/dpr-question_encoder-multiset-base and facebook/dpr-question_encoder-multiset-base\n",
      "/u/franzm/packages/minconda3/envs/primeqa_pyarrow/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "10/26/2022 15:42:47 transformer_optimize.py:92 - ***** Running training *****\n",
      "10/26/2022 15:42:47 transformer_optimize.py:93 -   Instantaneous batch size per GPU = 1\n",
      "10/26/2022 15:42:47 transformer_optimize.py:94 -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "10/26/2022 15:42:47 transformer_optimize.py:95 -   Gradient Accumulation steps = 1\n",
      "10/26/2022 15:42:47 transformer_optimize.py:96 -   Total optimization steps = 5\n",
      "10/26/2022 15:42:47 distloader_base.py:113 - completed files = [], count = 0\n",
      "10/26/2022 15:42:47 distloader_base.py:133 - epoch 1, pending files = ['../../../tests/resources/ir_dense/xorqa.train_ir_negs_5_poss_1_001pct_at_0pct_en.tsv'], count = 1\n",
      "10/26/2022 15:42:47 distloader_base.py:201 - on 0 rank, using files: ['../../../tests/resources/ir_dense/xorqa.train_ir_negs_5_poss_1_001pct_at_0pct_en.tsv'], shared: False\n",
      "10/26/2022 15:42:47 dataloader_biencoder.py:83 - out of 5 batches of size 1, pushed 0 out of batch due to conflict, 0 pushed out completely\n",
      "10/26/2022 15:42:47 biencoder_trainer.py:139 - len(self.batches) 5\n",
      "10/26/2022 15:42:47 dataloader_biencoder.py:165 - torch.Size([1, 13]) queries and torch.Size([2, 128]) contexts\n",
      "tensor([0])\n",
      "10/26/2022 15:42:48 dataloader_biencoder.py:167 -    query: [CLS] who maintained the throne for the longest time in china? [SEP]\n",
      "10/26/2022 15:42:48 dataloader_biencoder.py:168 -    query: tensor([ 101, 2040, 5224, 1996, 6106, 2005, 1996, 6493, 2051, 1999, 2859, 1029,\n",
      "         102])\n",
      "10/26/2022 15:42:48 dataloader_biencoder.py:169 - positive: [CLS] [SEP] kangxi emperor the kangxi emperor's reign of 61 years makes him the longest - reigning emperor in chinese history ( although his grandson, the qianlong emperor, had the longest period of \" de facto \" power ) and one of the longest - reigning rulers in the world. however, since he ascended the throne at the age of seven, actual power was held for six years by four regents and his grandmother, the grand empress dowager xiaozhuang. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "10/26/2022 15:42:48 dataloader_biencoder.py:170 - positive: tensor([  101,   102, 16073,  9048,  3750,  1996, 16073,  9048,  3750,  1005,\n",
      "         1055,  5853,  1997,  6079,  2086,  3084,  2032,  1996,  6493,  1011,\n",
      "        16323,  3750,  1999,  2822,  2381,  1006,  2348,  2010,  7631,  1010,\n",
      "         1996, 18816,  2319, 10052,  3750,  1010,  2018,  1996,  6493,  2558,\n",
      "         1997,  1000,  2139, 13743,  1000,  2373,  1007,  1998,  2028,  1997,\n",
      "         1996,  6493,  1011, 16323, 11117,  1999,  1996,  2088,  1012,  2174,\n",
      "         1010,  2144,  2002, 19644,  1996,  6106,  2012,  1996,  2287,  1997,\n",
      "         2698,  1010,  5025,  2373,  2001,  2218,  2005,  2416,  2086,  2011,\n",
      "         2176, 22832,  1998,  2010,  7133,  1010,  1996,  2882, 10248, 20508,\n",
      "        19523, 27922, 13860,  2290,  1012,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0])\n",
      "10/26/2022 15:42:48 dataloader_biencoder.py:171 - negative: [CLS] [SEP] chiddy bang new songs from the duo and in november 2009 debuted the group's first free mixtape entitled \" the swelly express \". on 28 april 2011 during the first - ever mtv o music awards, anamege broke the guinness world record for longest freestyle rap and longest marathon rapping record by freestyling for 9 hours, 18 minutes, and 22 seconds, stealing the throne from rapper m - eighty, who originally broke the record in 2009 by rapping for 9 hours, 15 minutes and 15 seconds. anamege had also beat canadian rapper d. o. for longest marathon rapping session, the previous [SEP]\n",
      "10/26/2022 15:42:48 dataloader_biencoder.py:172 - negative: tensor([  101,   102,  9610, 14968,  9748,  2047,  2774,  2013,  1996,  6829,\n",
      "         1998,  1999,  2281,  2268,  6006,  1996,  2177,  1005,  1055,  2034,\n",
      "         2489, 18713,  4709,  1000,  1996, 18370,  2100,  4671,  1000,  1012,\n",
      "         2006,  2654,  2258,  2249,  2076,  1996,  2034,  1011,  2412,  8692,\n",
      "         1051,  2189,  2982,  1010,  9617,  4168,  3351,  3631,  1996, 17323,\n",
      "         2088,  2501,  2005,  6493,  9817,  9680,  1998,  6493,  8589,  9680,\n",
      "         4691,  2501,  2011,  2489, 21756,  2989,  2005,  1023,  2847,  1010,\n",
      "         2324,  2781,  1010,  1998,  2570,  3823,  1010, 11065,  1996,  6106,\n",
      "         2013, 10687,  1049,  1011, 12021,  1010,  2040,  2761,  3631,  1996,\n",
      "         2501,  1999,  2268,  2011,  9680,  4691,  2005,  1023,  2847,  1010,\n",
      "         2321,  2781,  1998,  2321,  3823,  1012,  9617,  4168,  3351,  2018,\n",
      "         2036,  3786,  3010, 10687,  1040,  1012,  1051,  1012,  2005,  6493,\n",
      "         8589,  9680,  4691,  5219,  1010,  1996,  3025,   102])\n",
      "/u/franzm/packages/minconda3/envs/primeqa_pyarrow/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "10/26/2022 15:44:02 biencoder_trainer.py:78 - saving checkpoint to /tmp/tmpxyvdwant/output_dir/latest_checkpoint\n",
      "10/26/2022 15:44:05 biencoder_trainer.py:97 - saved checkpoint to /tmp/tmpxyvdwant/output_dir/latest_checkpoint\n",
      "10/26/2022 15:44:05 biencoder_trainer.py:173 - saving to /tmp/tmpxyvdwant/output_dir\n",
      "10/26/2022 15:44:07 biencoder_trainer.py:135 - Breaking, self.optimizer.should_continue() is False\n",
      "10/26/2022 15:44:07 biencoder_trainer.py:137 - Breaking, self.batches is None\n",
      "10/26/2022 15:44:07 biencoder_trainer.py:179 - All done\n",
      "10/26/2022 15:44:07 reporting.py:150 - ==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/26/2022 15:44:07 reporting.py:153 - loss = 0.016342264413827936\n",
      "10/26/2022 15:44:07 reporting.py:153 - accuracy = 1.0\n",
      "10/26/2022 15:44:07 biencoder_trainer.py:182 - saving to /tmp/tmpxyvdwant/output_dir\n",
      "10/26/2022 15:44:14 biencoder_trainer.py:184 - Took 1.4 minutes\n"
     ]
    }
   ],
   "source": [
    "with patch.object(sys, 'argv', model_training_args):\n",
    "    trainer = BiEncoderTrainer()\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e177c14",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "Next, we will index a collection of documents, using model representaion from the previous step. \n",
    "The collection is a TSV file, containing each document's ID, title, and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3778c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_fn = os.path.join(test_files_location, \"xorqa.train_ir_001pct_at_0_pct_collection_fornum.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8aac9",
   "metadata": {},
   "source": [
    "Here is an example document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa76aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Kangxi Emperor's reign of 61 years makes him the longest-reigning emperor in Chinese history (although his grandson, the Qianlong Emperor, had the longest period of \"de facto\" power) and one of the longest-reigning rulers in the world. However, since he ascended the throne at the age of seven, actual power was held for six years by four regents and his grandmother, the Grand Empress Dowager Xiaozhuang.</td>\n",
       "      <td>Kangxi Emperor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(collection_fn, sep='\\t', header=0, nrows=1)\n",
    "display(HTML(data.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba60e44",
   "metadata": {},
   "source": [
    "Here are the indexer arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccec72ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_args = [\n",
    "            \"prog\",\n",
    "            \"--dpr_ctx_encoder_path\", os.path.join(output_dir, \"ctx_encoder\"),\n",
    "            \"--embed\", \"1of1\",\n",
    "            \"--sharded_index\",\n",
    "            \"--batch_size\", \"1\",\n",
    "            \"--corpus\", os.path.join(test_files_location,\"xorqa.train_ir_001pct_at_0_pct_collection_fornum.tsv\"),\n",
    "            \"--output_dir\", output_dir]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a2887c",
   "metadata": {},
   "source": [
    "Next we run the indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af19bfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/26/2022 15:44:30 index_simple_corpus.py:107 - wrote passages_1_of_1.json.gz.records in 12 seconds\n",
      "10/26/2022 15:44:30 faiss_index.py:70 - building index, reading data from /tmp/tmpxyvdwant/output_dir/passages_1_of_1.json.gz.records, writing to /tmp/tmpxyvdwant/output_dir/index_1_of_1.faiss\n",
      "10/26/2022 15:44:30 faiss_index.py:138 - processed 0 passages\n",
      "10/26/2022 15:44:30 faiss_index.py:131 - calling index.add with 6 vectors\n",
      "10/26/2022 15:44:30 faiss_index.py:150 - processed 6 passages\n",
      "10/26/2022 15:44:30 faiss_index.py:151 - finished building index, writing index file to /tmp/tmpxyvdwant/output_dir/index_1_of_1.faiss\n",
      "10/26/2022 15:44:30 faiss_index.py:154 - took 0 seconds\n"
     ]
    }
   ],
   "source": [
    "with patch.object(sys, 'argv', indexing_args):\n",
    "    indexer = DPRIndexer()\n",
    "    indexer.index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c118dc06",
   "metadata": {},
   "source": [
    "The resulting index files are in output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1051960",
   "metadata": {},
   "source": [
    "## Search\n",
    "The easiest way to test the trained model is to use the searcher in a \"query list\" mode, where the searcher's search function is called with a list of queries as an argument.\n",
    "First, we initialize the searcher, pointing to the model we have trained, and the document index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f513bc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/26/2022 15:44:32 searcher.py:66 - Using default tokenizer in facebook/dpr-question_encoder-multiset-base.  If that is not what you want, specify the tokenizer in '--qry_tokenizer_path' argument.\n",
      "10/26/2022 15:44:32 searcher.py:82 - Using sharded faiss, reading shards from /tmp/tmpxyvdwant/output_dir\n",
      "10/26/2022 15:44:32 searcher.py:86 - Reading passages_1_of_1.json.gz.records\n",
      "10/26/2022 15:44:32 searcher.py:91 - Using sharded faiss with 1 shards.\n"
     ]
    }
   ],
   "source": [
    "search_args = [\n",
    "    \"prog\",\n",
    "    \"--model_name_or_path\", os.path.join(output_dir, \"qry_encoder\"),\n",
    "    \"--index_location\", output_dir,\n",
    "    \"--output_dir\", output_dir]  \n",
    "\n",
    "with patch.object(sys, 'argv', search_args):\n",
    "    searcher = DPRSearcher()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab15199a",
   "metadata": {},
   "source": [
    "Next, we run search for a query entered here as a one-element list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26e6d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_batch = ['Who maintained the throne for the longest time in China?']\n",
    "retrieved_doc_ids, passages = searcher.search(query_batch = query_batch, top_k = 1, mode = 'query_list')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d3c2d5",
   "metadata": {},
   "source": [
    "Here are the retrived results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed63e82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"titles\": [\n",
      "            \"Kangxi Emperor\"\n",
      "        ],\n",
      "        \"texts\": [\n",
      "            \"The Kangxi Emperor's reign of 61 years makes him the longest-reigning emperor in Chinese history (although his grandson, the Qianlong Emperor, had the longest period of \\\"de facto\\\" power) and one of the longest-reigning rulers in the world. However, since he ascended the throne at the age of seven, actual power was held for six years by four regents and his grandmother, the Grand Empress Dowager Xiaozhuang.\"\n",
      "        ],\n",
      "        \"scores\": [\n",
      "            91.072509765625\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(passages, indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddabf8d",
   "metadata": {},
   "source": [
    "Next, we use the trained model and the index to search the collection, reading queries from a TSV query file and saving the search results in a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce806187",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_fn = os.path.join(test_files_location, \"xorqa.train_ir_001pct_at_0_pct_queries_fornum_en.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4440730",
   "metadata": {},
   "source": [
    "Here are the search arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a18e13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_args = [\n",
    "    \"prog\",\n",
    "    \"--queries\", queries_fn,\n",
    "    \"--model_name_or_path\", os.path.join(output_dir, \"qry_encoder\"),\n",
    "    \"--bsize\", \"1\",\n",
    "    \"--index_location\", output_dir,\n",
    "    \"--output_dir\", output_dir,\n",
    "    \"--top_k\", \"1\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e32e490",
   "metadata": {},
   "source": [
    " Next we run the search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19acb0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/26/2022 15:44:35 searcher.py:66 - Using default tokenizer in facebook/dpr-question_encoder-multiset-base.  If that is not what you want, specify the tokenizer in '--qry_tokenizer_path' argument.\n",
      "10/26/2022 15:44:36 searcher.py:82 - Using sharded faiss, reading shards from /tmp/tmpxyvdwant/output_dir\n",
      "10/26/2022 15:44:36 searcher.py:86 - Reading passages_1_of_1.json.gz.records\n",
      "10/26/2022 15:44:36 searcher.py:91 - Using sharded faiss with 1 shards.\n",
      "10/26/2022 15:44:37 searcher.py:247 - Finished instance 1, 0.2711329205524996 per second.\n"
     ]
    }
   ],
   "source": [
    "with patch.object(sys, 'argv', search_args):\n",
    "    searcher = DPRSearcher()\n",
    "    searcher.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ca6cf",
   "metadata": {},
   "source": [
    "Search output is in .tsv format in `output_dir/ranked_passages.tsv` file containing query IDs, document IDs, ranks, and scores.\n",
    "Here are the actual values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11dbc220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7239279093922981232\t1\t0\t91.072509765625\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(output_dir, \"ranked_passages.tsv\"), 'r') as f:\n",
    "    for line in f.readlines():\n",
    "         print(line.rstrip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
