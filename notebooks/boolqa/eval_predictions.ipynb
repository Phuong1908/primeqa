{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e3ee16",
   "metadata": {},
   "source": [
    "# TydiQA - support for boolean questions\n",
    "\n",
    "Here we assume that you have used `run_mrc.py` with the `--do_boolean` option to decode the TydiQA dataset with full support for boolean questions.  See top-level README.md. There are four stages in the process:\n",
    "\n",
    "1. MRC (**M**achine **R**eading **C**omprehension) - given a question and and answer, find a representative span that may contain a short answer.  This is analyzed in detail in the `tydiqa.ipynb`\n",
    "2. QTC (**Q**uestion **T**ype **C**lassification) - given the question, decide if it is `boolean` or `short_answer`\n",
    "3. EVC (**Ev**idence **C**lassifier) - given a question and a short answer span, decide the short answer span supports `yes` or `no`.  This is analyzed in more detail in `evc.ipynb`.\n",
    "4. SN (**S**core **N**ormalization) - span scores may have different dynamic ranges according as whether the question is `boolean` or `short_anwer`.  Normalize them uniformally to $[0,1]$\n",
    "\n",
    "In this notebook, we will show what happened internally in each step of the operation by looking at intermediate files from the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fb65fe",
   "metadata": {},
   "source": [
    "# Intermediate files\n",
    "\n",
    "We will load some output/intermediate files from a recent command-line experiment with command\n",
    "```\n",
    "python primeqa/mrc/run_mrc.py --model_name_or_path PrimeQA/tydi-reader_bpes-xlmr_large-20221117 \\\n",
    "       --output_dir ${OUTPUT_DIR} --fp16 --do_eval \\\n",
    "       --per_device_eval_batch_size 128 --overwrite_output_dir \\\n",
    "       --postprocessor primeqa.boolqa.processors.postprocessors.extractive.ExtractivePipelinePostProcessor \\\n",
    "       --do_boolean --boolean_config primeqa/boolqa/tydi_boolqa_config.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f8f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrc_file=f'{base}/eval_predictions.json'\n",
    "qtc_file=f'{base}/qtc/predictions.json'\n",
    "evc_file=f'{base}/evc/predictions.json'\n",
    "out_file=f'{base}/sn/eval_predictions_processed.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee037d5d",
   "metadata": {},
   "source": [
    "# Display helper\n",
    "\n",
    "Our intermediate files have many fields - to display them better we use a helper routine to convert to dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800d9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from primeqa.boolqa.processors.dataset.mrc2dataset  import create_dataset_from_run_mrc_output\n",
    "\n",
    "from datasets import ClassLabel, Sequence\n",
    "from numpy.random import permutation\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Based on https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb\n",
    "def show_balanced_examples(dataset, perm, groups, nrows, maxchars, cols):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    dfp = df.iloc[perm] # shuffle\n",
    "    dfg = dfp.groupby(groups)\n",
    "    df_todisplay = dfg.head(nrows)[cols]\n",
    "    if 'passage_answer_text' in cols:\n",
    "        df_todisplay['passage_answer_text'] = df_todisplay['passage_answer_text'].str.slice(0,maxchars) + '...'\n",
    "    display(HTML(df_todisplay.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc682328",
   "metadata": {},
   "source": [
    "# Samples of MRC output\n",
    "\n",
    "Here we show `question`'s and the predicted answer `span_answer_text` for the random examples (one from each language.)  This is at the initial stage of question answering - a purely extractive system.  The confidence in the span answer is given by `span_answer_score`, which is a function of various other logits available in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a036fe9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>question</th>\n",
       "      <th>span_answer_text</th>\n",
       "      <th>language</th>\n",
       "      <th>span_answer_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2952</th>\n",
       "      <td>44d0fc1d-d9da-46c9-ba9a-b685e98db154</td>\n",
       "      <td>পৃথিবীর প্রথম মানচিত্রের নাম কী ?</td>\n",
       "      <td>এরাতোস্থেনেস</td>\n",
       "      <td>bengali</td>\n",
       "      <td>-0.668091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14958</th>\n",
       "      <td>3c3eaf7e-89e9-40ad-8547-e78c2b567623</td>\n",
       "      <td>Je,Arusha ina idadi ya watu wangapi?</td>\n",
       "      <td>23000</td>\n",
       "      <td>swahili</td>\n",
       "      <td>4.373718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1bff8109-bfa9-4e99-96cc-c72431a6b139</td>\n",
       "      <td>Saiko Suomi jatkosodassa sotasaaliiksi viisi 130/50 N -tykkiä?</td>\n",
       "      <td>Talvisodan synnyttämä revanssihenki oli osaltaan viemässä Suomea jatkosotaan.</td>\n",
       "      <td>finnish</td>\n",
       "      <td>-3.397400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10092</th>\n",
       "      <td>1b300284-f80b-4aad-a113-333906b38caf</td>\n",
       "      <td>apakah Ariana Grande seorang Heteroseksual?</td>\n",
       "      <td>Contoh</td>\n",
       "      <td>indonesian</td>\n",
       "      <td>-3.620056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11962</th>\n",
       "      <td>2cbccd85-62b7-4661-8386-bb37c10c525d</td>\n",
       "      <td>บีเวอร์ มีชื่อทางวิทยาศาสตร์ว่าอย่างไร?</td>\n",
       "      <td>Castor fiber</td>\n",
       "      <td>thai</td>\n",
       "      <td>6.416016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>4baf5b00-de62-4789-ba25-4affe428a2f4</td>\n",
       "      <td>2017 నాటికి ఆదిలక్ష్మాంబ పురం గ్రామంలో వ్యవసాయేతర వినియోగంలో ఉన్న భూమి ఎంత?</td>\n",
       "      <td>27.11</td>\n",
       "      <td>telugu</td>\n",
       "      <td>2.588379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13676</th>\n",
       "      <td>eaf55e82-7713-46c2-b913-23ed1130faa0</td>\n",
       "      <td>한국에서 가장 오래된 성당은 어디인가?</td>\n",
       "      <td>성공회 강화성당</td>\n",
       "      <td>korean</td>\n",
       "      <td>6.465332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14561</th>\n",
       "      <td>5507963f-9a14-491c-9cdf-7390991eed49</td>\n",
       "      <td>Как зовут главного персонажа фильма «Рэкет» (1951)?</td>\n",
       "      <td>Ник Скэнлон</td>\n",
       "      <td>russian</td>\n",
       "      <td>4.588623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16500</th>\n",
       "      <td>23da52e4-119d-4082-9c45-8521b79ae3f7</td>\n",
       "      <td>Where did the Meiji Restoration take place?</td>\n",
       "      <td>Empire of Japan</td>\n",
       "      <td>english</td>\n",
       "      <td>6.046127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15484</th>\n",
       "      <td>7ff4cc0c-a8fe-4c79-8e23-29458f0d4926</td>\n",
       "      <td>ロストラの大きさは？</td>\n",
       "      <td>大きな</td>\n",
       "      <td>japanese</td>\n",
       "      <td>-5.183105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11023</th>\n",
       "      <td>df80c5d9-3148-4298-9a0d-30a7e4e3ba2a</td>\n",
       "      <td>من هم القحطانيون؟</td>\n",
       "      <td>القبائل التي تعود بأصلها إلى جد مشترك عرف عند النسابة والإخباريين العرب باسم قحطان</td>\n",
       "      <td>arabic</td>\n",
       "      <td>8.031799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_examples=create_dataset_from_run_mrc_output(mrc_file, unpack=False)\n",
    "random_idxs = permutation(len(eval_examples))\n",
    "\n",
    "cols=['example_id','question','span_answer_text','language', 'span_answer_score']\n",
    "show_balanced_examples(eval_examples, random_idxs, 'language', 1, 100, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d03e09",
   "metadata": {},
   "source": [
    "# Samples of QTC output\n",
    "\n",
    "At this stage, two fields have been added: `question_type_pred` which is `boolean` if the question is a boolean question, and `short_answer` if the question is not boolean - typically factoid in this dataset.\n",
    "The other field `question_type_scores` contains the classifier scores (logits) for each class. \n",
    "By far the majority of questions in TydiQA are `short_answer`: we present random examples chosen equally from those predicted `boolean` and those predicted `short_answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e9a3da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720ec24d8f6444f5888eea6e97d58640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_type_pred</th>\n",
       "      <th>question_type_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>6435f62e-c90f-4222-a0a2-10e673285bf6</td>\n",
       "      <td>How many metropolitan areas does Route 64 pass through?</td>\n",
       "      <td>other</td>\n",
       "      <td>{'boolean': -3.2897751331329346, 'other': 3.0375118255615234}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>8aef6ed1-209c-49e1-94b8-a00b916b9e69</td>\n",
       "      <td>What can we do with metal–organic frameworks?</td>\n",
       "      <td>other</td>\n",
       "      <td>{'boolean': -2.8831963539123535, 'other': 2.6908504962921143}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>38f0b151-1346-4072-80fb-d7bc03eedb3c</td>\n",
       "      <td>Is oiliness of the skin considered a disease?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.482534170150757, 'other': -3.5299534797668457}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>fe4ddaa6-264c-4786-b3ba-257f19040957</td>\n",
       "      <td>When did the term gypsy develop to describe Romanis?</td>\n",
       "      <td>other</td>\n",
       "      <td>{'boolean': -3.3366098403930664, 'other': 3.031615734100342}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>cb702fcd-e348-4d20-b8fe-dc541ae05378</td>\n",
       "      <td>What percentage of people experience relapse after recovering from addiction?</td>\n",
       "      <td>other</td>\n",
       "      <td>{'boolean': -2.444016695022583, 'other': 2.1554253101348877}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2459bd3e-add5-49ea-a6e1-5a360d494bf4</td>\n",
       "      <td>When did Jean Anna Fau die?</td>\n",
       "      <td>other</td>\n",
       "      <td>{'boolean': -3.435251474380493, 'other': 3.13974666595459}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>68ee1a17-9720-41da-b31f-757a78125001</td>\n",
       "      <td>Does Mary Hoffman have kids?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.476332187652588, 'other': -3.555983066558838}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>ebce63e0-78bd-4685-92f0-db5294d6cecb</td>\n",
       "      <td>Does Google autotranslate all pages?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.4442615509033203, 'other': -3.4900364875793457}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>044b1b49-906e-4b23-b354-8ca7be9881ef</td>\n",
       "      <td>Does Donna Troy have any superpowers?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.4369497299194336, 'other': -3.508683681488037}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>f6b04fa0-e30e-4a26-a579-90eb0ea3f3b2</td>\n",
       "      <td>Can salt marsh die-off be fixed?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.4441893100738525, 'other': -3.5055618286132812}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_examples=create_dataset_from_run_mrc_output(qtc_file, unpack=False)\n",
    "english_eval_examples = eval_examples.filter(lambda x:x['language']=='english')\n",
    "random_idxs = permutation(len(english_eval_examples))\n",
    "cols=['example_id','question','question_type_pred', 'question_type_scores']\n",
    "show_balanced_examples(english_eval_examples, random_idxs, 'question_type_pred', 5, 100, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9dfa92",
   "metadata": {},
   "source": [
    "# Samples of EVC output \n",
    "As above this classifier adds two new fields.  `boolean_answer_pred` is `yes` if the predicted answer to a boolean question is positive/true/yes, `no` if the answer is negative/false/no.   The field `boolean_answer_scores` provides the scores (logits) of each class.\n",
    "\n",
    "\n",
    "For presentation purposes, we select the English questions from the dev set (they are not scored by tydi_eval.py), which have a higher fraction of boolean questions.  The boolean questions in the tydi dataset are overwhelmingly biased towards having a `yes` rather than a `no`  as the answer.  We suspect that the question writers were attempting to confirm existing knowledge.\n",
    "Note that the answer classifier runs on all questions, even on the short answer questions, for simplicity.  A real deployed system would run the answer classifier only on questions that are predicted to be boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b6ae96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01250c19275545b6a52d013994e27116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>question</th>\n",
       "      <th>passage_answer_text</th>\n",
       "      <th>boolean_answer_pred</th>\n",
       "      <th>boolean_answer_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>4aa91b84-9653-4019-8cc1-eb9580b7a654</td>\n",
       "      <td>Does Frankfurt have a regional dish?</td>\n",
       "      <td>Handkäse (pronounced[ˈhantkɛːzə]; literally: \"hand cheese\") is a German regional sour milk cheese (similar to Harzer) and is a culinary speciality of Frankfurt am Main, Offenbach am Main, Darmstadt, Langen, and other parts of southern Hesse. It gets its name from the traditional way of producing it:...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -5.016531944274902, 'yes': 4.2546706199646}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2f229467-f0c9-4d9f-a919-9076467d0444</td>\n",
       "      <td>Do fungus spread by spores?</td>\n",
       "      <td>The fungi produce asexual spores which disperse by wind, water or by insect vectors[9] spreading the infection....</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -4.835036277770996, 'yes': 3.925503969192505}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36af5968-9d7a-4139-a678-531f205db4d3</td>\n",
       "      <td>Is Hungarian a romance language?</td>\n",
       "      <td>Additionally, the letter pairs ⟨ny⟩, ⟨ty⟩, and ⟨gy⟩ represent the palatal consonants /ɲ/, /c/, and /ɟ/ (a little like the \"d+y\" sounds in British \"du&lt;/i&gt;ke\" or American \"woul&lt;i data-parsoid='{\"dsr\":[64312,64319,2,2]}'&gt;d y&lt;/i&gt;ou\")—a bit like saying \"d\" with the tongue pointing to the palate....</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 4.103992938995361, 'yes': -3.6571133136749268}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>111824a0-a13a-4c23-b591-cbbf5eff4a9f</td>\n",
       "      <td>Is Thailand apart of China?</td>\n",
       "      <td>China – Thailand relations officially started in November 1975 after years of negotiations.[1][2] For a long time, Thailand, or in its former name, Siam, was a very strong and loyal Sinophilic country, and usually the Chinese issued Siam with a strong respect from China to ensure its alliance with t...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 2.0598034858703613, 'yes': -1.898944616317749}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2e5f01f0-b22c-4afe-a568-4a9eb1e1c2da</td>\n",
       "      <td>Is communism the same as socialism?</td>\n",
       "      <td>In addition to this, the term communism (as well as socialism) is often used to refer to those political and economic systems and states dominated by a political, bureaucratic class, typically attached to one single Communist party that follow Marxist-Leninist doctrines and often claim to represent ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -4.715367794036865, 'yes': 3.6751482486724854}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>094443ee-0bb1-4d8b-98e1-540c69cea311</td>\n",
       "      <td>Is steam still used in some trains?</td>\n",
       "      <td>From the early 1900s steam locomotives were gradually superseded by electric and diesel locomotives, with railways fully converting to electric and diesel power beginning in the late 1930s. The majority of steam locomotives were retired from regular service by the 1980s, though several continue to r...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 2.094043254852295, 'yes': -1.9507315158843994}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>631a9a40-746a-448e-8c73-31e5ee11510b</td>\n",
       "      <td>Did Emmylou Harris go to college?</td>\n",
       "      <td>Harris is from a career military family. Her father, Walter Harris (1921-1993),[2] was a Marine Corps officer, and her mother, Eugenia (1921-2014),[3] was a wartime military wife. Her father was reported missing in action in Korea in 1952 and spent ten months as a prisoner of war. Born in Birmingham...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -4.775354862213135, 'yes': 4.165227890014648}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>44091813-f673-47b1-902f-6a96557221a7</td>\n",
       "      <td>Can the central nervous system heal itself?</td>\n",
       "      <td>Nervous system injuries affect over 90,000 people every year.[2] It is estimated that spinal cord injuries alone affect 10,000 each year.[3] As a result of this high incidence of neurological injuries, nerve regeneration and repair, a subfield of neural tissue engineering, is becoming a rapidly grow...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -4.795304298400879, 'yes': 3.9687118530273438}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>aa6b0971-4aa1-4594-8006-b117b869e9a9</td>\n",
       "      <td>Is the great horned owl endangered?</td>\n",
       "      <td>The great horned owl is not considered a globally threatened species by the IUCN.[1] Including the Magellanic species, there are approximately 5.3 million wild horned owls in the Americas.[7] Most mortality in modern times is human-related, caused by owls flying into man-made objects, including buil...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 4.286905288696289, 'yes': -3.9321670532226562}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>d2424a99-1125-41a5-85bf-62c0309feee6</td>\n",
       "      <td>Is the Mauser C96 produced today?</td>\n",
       "      <td>A version of the Mauser pistol with a full-sized grip, six-shot internal magazine, and a 120-millimetre (4.7in) barrel. Production was phased out by 1899....</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 4.3284735679626465, 'yes': -4.126214981079102}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_examples=create_dataset_from_run_mrc_output(evc_file, unpack=False)\n",
    "english_boolean_eval_examples = eval_examples.filter(lambda x:x['language']=='english' and x['question_type_pred']=='boolean')\n",
    "random_idxs = permutation(len(english_boolean_eval_examples))\n",
    "cols=['example_id','question','passage_answer_text', 'boolean_answer_pred', 'boolean_answer_scores']\n",
    "show_balanced_examples(english_boolean_eval_examples, random_idxs, 'boolean_answer_pred', 5, 300, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4803b9a",
   "metadata": {},
   "source": [
    "# Final output\n",
    "\n",
    "The final output file is in a format suitable for the tydi evalutation script and contains no textual information.  The `confidence_score` is normalized to `[0,1]` by the score normalizer based the confidence score of the original mrc output, and the prediction of the question type classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "550f2f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>passage_index</th>\n",
       "      <th>yes_no_answer</th>\n",
       "      <th>confidence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353a941a-b57a-4e36-8e55-0d5963694022</td>\n",
       "      <td>986</td>\n",
       "      <td>1020</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.916934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab4c6470-4fb9-4ff0-b439-0ca8ffdf7e60</td>\n",
       "      <td>371</td>\n",
       "      <td>388</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.101929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06b1a008-5c3f-4f59-8b6c-bfc1bd3e9b52</td>\n",
       "      <td>14805</td>\n",
       "      <td>14807</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8f4612a0-eae9-4f32-a4d2-4a2b6dc848c2</td>\n",
       "      <td>5993</td>\n",
       "      <td>6010</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0cf6e728-1925-49a1-80ff-4d19b3efb538</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18665</th>\n",
       "      <td>417a5750-e4d3-4b2f-af60-278498883693</td>\n",
       "      <td>176</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18666</th>\n",
       "      <td>d264bbbd-9dcf-4bb8-b467-fbba0d0b6fe0</td>\n",
       "      <td>183</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18667</th>\n",
       "      <td>2f7b0365-33e2-4a26-ba2c-0a1f087a4939</td>\n",
       "      <td>1483</td>\n",
       "      <td>1488</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18668</th>\n",
       "      <td>3141a8e2-979f-4fca-aca9-1fba6a6f90e4</td>\n",
       "      <td>723</td>\n",
       "      <td>731</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18669</th>\n",
       "      <td>9162513e-59be-46e3-92cc-49d895ab72e5</td>\n",
       "      <td>1455</td>\n",
       "      <td>1461</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18670 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 example_id  start_position  end_position  \\\n",
       "0      353a941a-b57a-4e36-8e55-0d5963694022             986          1020   \n",
       "1      ab4c6470-4fb9-4ff0-b439-0ca8ffdf7e60             371           388   \n",
       "2      06b1a008-5c3f-4f59-8b6c-bfc1bd3e9b52           14805         14807   \n",
       "3      8f4612a0-eae9-4f32-a4d2-4a2b6dc848c2            5993          6010   \n",
       "4      0cf6e728-1925-49a1-80ff-4d19b3efb538               1            22   \n",
       "...                                     ...             ...           ...   \n",
       "18665  417a5750-e4d3-4b2f-af60-278498883693             176           185   \n",
       "18666  d264bbbd-9dcf-4bb8-b467-fbba0d0b6fe0             183           192   \n",
       "18667  2f7b0365-33e2-4a26-ba2c-0a1f087a4939            1483          1488   \n",
       "18668  3141a8e2-979f-4fca-aca9-1fba6a6f90e4             723           731   \n",
       "18669  9162513e-59be-46e3-92cc-49d895ab72e5            1455          1461   \n",
       "\n",
       "       passage_index  yes_no_answer  confidence_score  \n",
       "0                  2              0          0.916934  \n",
       "1                  1              0          0.101929  \n",
       "2                 27              0          0.104343  \n",
       "3                 12              0          0.082423  \n",
       "4                  0              0          0.171585  \n",
       "...              ...            ...               ...  \n",
       "18665              0              0          0.581892  \n",
       "18666              0              0          0.064176  \n",
       "18667              4              0          0.061807  \n",
       "18668              3              0          0.061466  \n",
       "18669              3              0          0.059766  \n",
       "\n",
       "[18670 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce7923e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
