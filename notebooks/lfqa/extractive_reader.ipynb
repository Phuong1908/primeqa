{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
      "{\"time\":\"2023-02-16 18:42:45,362\", \"name\": \"faiss.loader\", \"level\": \"INFO\", \"message\": \"Loading faiss.\"}\n",
      "{\"time\":\"2023-02-16 18:42:45,391\", \"name\": \"faiss.loader\", \"level\": \"INFO\", \"message\": \"Successfully loaded faiss.\"}\n"
     ]
    }
   ],
   "source": [
    "from primeqa.components.retriever.dense import ColBERTRetriever\n",
    "from primeqa.components.reader.extractive import ExtractiveReader\n",
    "from primeqa.pipelines.qa_pipeline import QAPipeline\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 16, 18:43:03] #> base_config.py from_path /dccstor/mabornea1/kilt-wikipedia-test/colbert_ir/kilt_wikipedia_eli5_dev_exp/indexes//kilt_wikipedia_eli5_dev_indname/metadata.json\n",
      "[Feb 16, 18:43:03] #> base_config.py from_path args loaded! \n",
      "[Feb 16, 18:43:03] #> base_config.py from_path args replaced ! \n",
      "[Feb 16, 18:43:10] #>>>>> at ColBERT name (model type) : /dccstor/colbert-ir/franzm/experiments/oct2_7_12_1.5e-06/none/2022-10/09/15.21.39/checkpoints/colbert.dnn.batch_91287.model\n",
      "[Feb 16, 18:43:10] #>>>>> at BaseColBERT name (model type) : /dccstor/colbert-ir/franzm/experiments/oct2_7_12_1.5e-06/none/2022-10/09/15.21.39/checkpoints/colbert.dnn.batch_91287.model\n",
      "[Feb 16, 18:43:23] factory model type: xlm-roberta-large\n",
      "[Feb 16, 18:43:46] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Feb 16, 18:43:54] get query model type: xlm-roberta-large\n",
      "[Feb 16, 18:43:55] get doc model type: xlm-roberta-large\n",
      "[Feb 16, 18:43:56] #> Loading codec...\n",
      "[Feb 16, 18:43:56] #> base_config.py from_path /dccstor/mabornea1/kilt-wikipedia-test/colbert_ir/kilt_wikipedia_eli5_dev_exp/indexes//kilt_wikipedia_eli5_dev_indname/metadata.json\n",
      "[Feb 16, 18:43:56] #> base_config.py from_path args loaded! \n",
      "[Feb 16, 18:43:56] #> base_config.py from_path args replaced ! \n",
      "[Feb 16, 18:43:56] #> Loading IVF...\n",
      "[Feb 16, 18:43:56] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dccstor/mabornea1/miniconda3/envs/prompt_reader/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 16, 18:43:58] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Feb 16, 18:43:59] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    }
   ],
   "source": [
    "# setup ColBERT index\n",
    "index_root = \"/dccstor/colbert-ir/franzm/indexes/oct2_10_11/oct2_10_11_exp/indexes/\"\n",
    "index_name = \"oct2_10_11_indname\"\n",
    "collection = \"/dccstor/avi7/neural_ir/colbert/data/psgs_w100.tsv\"\n",
    "\n",
    "retriever = ColBERTRetriever(index_root = index_root, \n",
    "                                     index_name = index_name, \n",
    "                                     collection = collection, \n",
    "                                     max_num_documents = 3)\n",
    "retriever.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"time\":\"2023-02-16 18:45:36,616\", \"name\": \"ExtractiveQAHead\", \"level\": \"INFO\", \"message\": \"Loading dropout value 0.1 from config attribute 'hidden_dropout_prob'\"}\n",
      "{\"time\":\"2023-02-16 18:45:37,296\", \"name\": \"XLMRobertaModelForDownstreamTasks\", \"level\": \"INFO\", \"message\": \"Setting task head for first time to 'None'\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reader = ExtractiveReader()\n",
    "reader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14635it [00:00, 199177.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# setup the pipeline\n",
    "pipeline = QAPipeline(retriever, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 31.76it/s]\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47865d77633a4cb28c9a98465cc97c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on eval dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"time\":\"2023-02-16 18:45:52,383\", \"name\": \"primeqa.mrc.trainers.mrc\", \"level\": \"INFO\", \"message\": \"The following columns in the evaluation set  don't have a corresponding argument in `XLMRobertaModelForDownstreamTasks.forward` and have been ignored: offset_mapping, example_idx, example_id, context_idx.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 96.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"0\": {\n",
      "        \"answers\": [\n",
      "            {\n",
      "                \"example_id\": \"0\",\n",
      "                \"passage_index\": 0,\n",
      "                \"span_answer_text\": \"54\",\n",
      "                \"span_answer\": {\n",
      "                    \"start_position\": 193,\n",
      "                    \"end_position\": 195\n",
      "                },\n",
      "                \"span_answer_score\": 0.8693150281906128,\n",
      "                \"confidence_score\": 0.6206434761820644\n",
      "            },\n",
      "            {\n",
      "                \"example_id\": \"0\",\n",
      "                \"passage_index\": 0,\n",
      "                \"span_answer_text\": \"54 different countries\",\n",
      "                \"span_answer\": {\n",
      "                    \"start_position\": 193,\n",
      "                    \"end_position\": 215\n",
      "                },\n",
      "                \"span_answer_score\": -0.03773808479309082,\n",
      "                \"confidence_score\": 0.25056132267301284\n",
      "            },\n",
      "            {\n",
      "                \"example_id\": \"0\",\n",
      "                \"passage_index\": 0,\n",
      "                \"span_answer_text\": \"54 different countries in Africa\",\n",
      "                \"span_answer\": {\n",
      "                    \"start_position\": 193,\n",
      "                    \"end_position\": 225\n",
      "                },\n",
      "                \"span_answer_score\": -0.7032182216644287,\n",
      "                \"confidence_score\": 0.12879520114492268\n",
      "            }\n",
      "        ],\n",
      "        \"passages\": [\n",
      "            \"Economy of Africa\\n Economy of Africa The economy of Africa consists of the trade, industry, agriculture, and human resources of the continent. , approximately 1.3 billion people were living in 54 different countries in Africa. Africa is a resource-rich continent. Recent growth has been due to growth in sales in commodities, services, and manufacturing. West Africa, East Africa, Central Africa and Southern Africa in particular, are expected to reach a combined GDP of $29 trillion by 2050.\",\n",
      "            \"List of Tour de France general classification winners\\n \\\"This is a list of the Tour de France general classification winners. The Tour de France is an annual road bicycle race held over 23 days in July. Established in 1903 by newspaper \\\"\\\"L'Auto\\\"\\\", the Tour is the most well-known and prestigious of cycling's three \\\"\\\"Grand Tours\\\"\\\"; the others are the Giro d'Italia and the Vuelta a Espa\\u00f1a. The race usually covers approximately 3,500 kilometres (2,200 mi), passing through France and neighbouring countries such as Belgium. The race is broken into day-long stages. Individual finishing times for each stage are totalled to determine the overall winner at the end of\\\"\",\n",
      "            \"Illegal taxicab operation\\n \\\"Crowdsourced taxis are run by a transportation network company such as Lyft and Uber, which operates in 633 cities worldwide. These companies develop, market, and operate the mobile apps, which allows consumers to submit a trip request which is then routed to sharing economy drivers. Since Uber's launch, several other companies have emulated its business model, a trend that has come to be referred to as \\\"\\\"Uberification\\\"\\\".\\\"\"\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\"number of participating countries in tour de france 2018 ?\"]\n",
    "answers = pipeline.run(questions, use_retriever=True)\n",
    "print(json.dumps(answers, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "c5d039775dffd761dc362a240b88aab365529f2df8e87d6e6e9eecd3e8d89fd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
