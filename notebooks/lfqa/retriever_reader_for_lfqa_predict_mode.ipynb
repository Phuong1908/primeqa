{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions for creating a ColBERT index and for training an FiD model for KILT-ELI5 can be found [here](https://github.com/primeqa/primeqa/blob/main/examples/lfqa/README.md)<br>  \n",
    "The ColBERT index is based on the KILT-Wikipedia corpus and an FiD reader is trained on KILT-ELI5.<br>\n",
    "This code requires 300GB memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T12:52:05.361802Z",
     "iopub.status.busy": "2022-11-11T12:52:05.361628Z",
     "iopub.status.idle": "2022-11-11T13:09:30.478107Z",
     "shell.execute_reply": "2022-11-11T13:09:30.477697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
      "{\"time\":\"2023-02-03 12:11:58,301\", \"name\": \"faiss.loader\", \"level\": \"INFO\", \"message\": \"Loading faiss.\"}\n",
      "{\"time\":\"2023-02-03 12:11:58,777\", \"name\": \"faiss.loader\", \"level\": \"INFO\", \"message\": \"Successfully loaded faiss.\"}\n",
      "[Feb 03, 12:12:10] #> base_config.py from_path /dccstor/mabornea1/kilt-wikipedia-test/colbert_ir/kilt_wikipedia_eli5_dev_exp/indexes//kilt_wikipedia_eli5_dev_indname/metadata.json\n",
      "[Feb 03, 12:12:10] #> base_config.py from_path args loaded! \n",
      "[Feb 03, 12:12:10] #> base_config.py from_path args replaced ! \n",
      "[Feb 03, 12:12:29] #>>>>> at ColBERT name (model type) : /dccstor/colbert-ir/franzm/experiments/oct2_7_12_1.5e-06/none/2022-10/09/15.21.39/checkpoints/colbert.dnn.batch_91287.model\n",
      "[Feb 03, 12:12:29] #>>>>> at BaseColBERT name (model type) : /dccstor/colbert-ir/franzm/experiments/oct2_7_12_1.5e-06/none/2022-10/09/15.21.39/checkpoints/colbert.dnn.batch_91287.model\n",
      "[Feb 03, 12:12:41] factory model type: xlm-roberta-large\n",
      "[Feb 03, 12:13:01] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Feb 03, 12:13:38] get query model type: xlm-roberta-large\n",
      "[Feb 03, 12:13:39] get doc model type: xlm-roberta-large\n",
      "[Feb 03, 12:13:40] #> Loading codec...\n",
      "[Feb 03, 12:13:40] #> base_config.py from_path /dccstor/mabornea1/kilt-wikipedia-test/colbert_ir/kilt_wikipedia_eli5_dev_exp/indexes//kilt_wikipedia_eli5_dev_indname/metadata.json\n",
      "[Feb 03, 12:13:40] #> base_config.py from_path args loaded! \n",
      "[Feb 03, 12:13:40] #> base_config.py from_path args replaced ! \n",
      "[Feb 03, 12:13:40] #> Loading IVF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dccstor/mabornea1/miniconda3/envs/prompt_reader/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 03, 12:13:40] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Feb 03, 12:14:06] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Feb 03, 12:14:33] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14635it [00:00, 95800.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 03, 12:15:08] #> XMLR QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "[Feb 03, 12:15:08] #> Input: $ What causes the trail behind jets at high altitude?, \t\t True, \t\t None\n",
      "[Feb 03, 12:15:08] #> Output IDs: torch.Size([32]), tensor([     0,   9748,   4865, 113660,     70, 141037,  50155,     55,    933,\n",
      "            99,  11192,    144,  35810,     32,      2,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1])\n",
      "[Feb 03, 12:15:08] #> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "[Feb 03, 12:15:08] #>>>> colbert query ==\n",
      "[Feb 03, 12:15:08] #>>>>> input_ids: torch.Size([32]), tensor([     0,   9748,   4865, 113660,     70, 141037,  50155,     55,    933,\n",
      "            99,  11192,    144,  35810,     32,      2,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/dccstor/mabornea1/miniconda3/envs/prompt_reader/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 03, 12:15:09] #>>>> before linear query ==\n",
      "[Feb 03, 12:15:09] #>>>>> Q: torch.Size([32, 1024]), tensor([[-0.9069, -0.0403,  1.6935,  ..., -2.0556, -0.3505,  0.3143],\n",
      "        [-0.6235, -0.2982,  0.1217,  ...,  0.0441, -1.5926, -0.2264],\n",
      "        [-0.4985, -0.5053, -0.0043,  ...,  0.1960, -1.3059, -0.4401],\n",
      "        ...,\n",
      "        [-1.5241, -0.1893,  0.4258,  ...,  0.2577, -1.6957, -0.0245],\n",
      "        [-1.5241, -0.1893,  0.4258,  ...,  0.2577, -1.6957, -0.0245],\n",
      "        [-1.5241, -0.1893,  0.4258,  ...,  0.2577, -1.6957, -0.0245]])\n",
      "[Feb 03, 12:15:09] #>>>>> self.linear query : Parameter containing:\n",
      "tensor([[-0.0301, -0.0307, -0.0115,  ..., -0.0231, -0.0023, -0.0216],\n",
      "        [ 0.0053,  0.0023, -0.0308,  ...,  0.0108,  0.0011,  0.0201],\n",
      "        [-0.0220,  0.0370,  0.0339,  ..., -0.0023, -0.0172,  0.0244],\n",
      "        ...,\n",
      "        [ 0.0222,  0.0115, -0.0246,  ...,  0.0389, -0.0034, -0.0165],\n",
      "        [-0.0146,  0.0392,  0.0131,  ..., -0.0055,  0.0219, -0.0368],\n",
      "        [ 0.0071,  0.0256, -0.0346,  ...,  0.0322,  0.0370,  0.0437]],\n",
      "       requires_grad=True)\n",
      "[Feb 03, 12:15:09] #>>>> colbert query ==\n",
      "[Feb 03, 12:15:09] #>>>>> Q: torch.Size([32, 128]), tensor([[-0.6141, -0.0460, -0.0425,  ..., -0.3479, -0.5222, -0.3503],\n",
      "        [ 0.1191, -1.1724,  0.6583,  ..., -0.1719, -0.6755,  0.7421],\n",
      "        [ 0.0661, -1.2071,  0.6980,  ..., -0.3364, -0.7605,  0.8986],\n",
      "        ...,\n",
      "        [-0.2243, -0.7942,  0.3333,  ...,  0.1308, -0.7902,  0.1236],\n",
      "        [-0.2243, -0.7942,  0.3333,  ...,  0.1308, -0.7902,  0.1236],\n",
      "        [-0.2243, -0.7942,  0.3333,  ...,  0.1308, -0.7902,  0.1236]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 45.09it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300754d8ca0b43bbb09c453b7f80576d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on eval dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BartFiDModelForDownstreamTasks.forward` and have been ignored: example_id. If example_id are not expected by `BartFiDModelForDownstreamTasks.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 01:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"example_id\": \"0\",\n",
      "        \"text\": \"The water vapor in the exhaust from the engine is mixed with the cold air, and condenses into droplets or ice crystals. \\n\\nThe water is then carried away by the wind, and the air is heated up, and then cooled down.  The water vapor condenses back into droplet form, and is then blown away by wind.  \\nThe air is then heated up again, and it condenses again, creating a cloud.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from primeqa.components.retriever.dense import ColBERTRetriever\n",
    "from primeqa.components.reader.generative import GenerativeFiDReader\n",
    "from primeqa.pipelines.qa_pipeline import QAPipeline\n",
    "import json\n",
    "\n",
    "index_root = \"/dccstor/mabornea1/kilt-wikipedia-test/colbert_ir/kilt_wikipedia_eli5_dev_exp/indexes/\"\n",
    "index_name = \"kilt_wikipedia_eli5_dev_indname\"\n",
    "collection = \"/dccstor/mabornea1/kilt-wikipedia-test/passages/kilt_knowledgesource_eli5_dev.tsv\"\n",
    "\n",
    "\n",
    "colbert_retriever = ColBERTRetriever(index_root = index_root, \n",
    "                                     index_name = index_name, \n",
    "                                     collection = collection, \n",
    "                                     max_num_documents = 3)\n",
    "colbert_retriever.load()\n",
    "\n",
    "fid_reader = GenerativeFiDReader()\n",
    "fid_reader.load()\n",
    "\n",
    "lfqa_pipeline = QAPipeline(colbert_retriever, fid_reader)\n",
    "\n",
    "questions = [\"What causes the trail behind jets at high altitude?\"]\n",
    "answers = lfqa_pipeline.run(questions)\n",
    "print(json.dumps(answers, indent=4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.45it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3785217ef34ef6b50d022920c1c682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on eval dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BartFiDModelForDownstreamTasks.forward` and have been ignored: example_id. If example_id are not expected by `BartFiDModelForDownstreamTasks.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"example_id\": \"0\",\n",
      "        \"text\": \"The idea is that the higher the income, the more you earn, the higher your tax burden. \\n\\nIf you make $100,000, you pay $100.00 in taxes. If you make a million, you only pay $50,000 in taxes, and you pay the same amount of taxes on all of your income.  \\nIf your income is $100k, you're paying $50k in taxes on $100K.  If you earn $100m, you are paying $100M in taxes and you're only paying $60K in taxes - you're still paying $40K in tax.  You're still only paying the same percentage of your money.  So you're not paying the full amount of your $100mil.  But you're also paying the exact same amount as someone who makes $100 million.  That's why you're in the same bracket. \\n\\n\\nIf someone makes $200m, they pay $200M in tax, and they're paying the $50K tax.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "questions = [\"Why do we have different tax brackets ? \"]\n",
    "answers = lfqa_pipeline.run(questions)\n",
    "print(json.dumps(answers, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt_reader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "c5d039775dffd761dc362a240b88aab365529f2df8e87d6e6e9eecd3e8d89fd4"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "13602d68c84c47bf855058690bcbb4d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "39225597f2cd4f8a9220793edecfc520": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7a378f82e08b4928ab8121940823c0fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_951479c9126444b3ae4b1700349569a6",
       "placeholder": "​",
       "style": "IPY_MODEL_ff5d6d4401c14e448104fe0ce8460106",
       "value": "Running tokenizer on eval dataset: 100%"
      }
     },
     "951479c9126444b3ae4b1700349569a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc825f54d0e3479c8d531ecf1f65224d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e0e466f2c69546f7af50ddb480defe0a",
       "placeholder": "​",
       "style": "IPY_MODEL_13602d68c84c47bf855058690bcbb4d4",
       "value": " 1/1 [00:00&lt;00:00,  5.78ba/s]"
      }
     },
     "e0e466f2c69546f7af50ddb480defe0a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3b07ee914ef448da819b0375e1dfc7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ed9d9367bbd840358cdae26cebfa194f",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_39225597f2cd4f8a9220793edecfc520",
       "value": 1
      }
     },
     "ed9d9367bbd840358cdae26cebfa194f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f42bb66471d2494facaf46d3fb1c8f9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7a378f82e08b4928ab8121940823c0fd",
        "IPY_MODEL_e3b07ee914ef448da819b0375e1dfc7f",
        "IPY_MODEL_dc825f54d0e3479c8d531ecf1f65224d"
       ],
       "layout": "IPY_MODEL_f792b945510749be99aa69889f3a3dc6"
      }
     },
     "f792b945510749be99aa69889f3a3dc6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ff5d6d4401c14e448104fe0ce8460106": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
